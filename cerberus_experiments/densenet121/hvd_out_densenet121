[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,4]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,4]<stderr>:Instructions for updating:
[1,4]<stderr>:Colocations handled automatically by placer.
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,14]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,14]<stderr>:Instructions for updating:
[1,14]<stderr>:Colocations handled automatically by placer.
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,6]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,6]<stderr>:Instructions for updating:
[1,6]<stderr>:Colocations handled automatically by placer.
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,12]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,12]<stderr>:Instructions for updating:
[1,12]<stderr>:Colocations handled automatically by placer.
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,7]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,7]<stderr>:Instructions for updating:
[1,7]<stderr>:Colocations handled automatically by placer.
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,5]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,5]<stderr>:Instructions for updating:
[1,5]<stderr>:Colocations handled automatically by placer.
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,15]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,15]<stderr>:Instructions for updating:
[1,15]<stderr>:Colocations handled automatically by placer.
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,8]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,8]<stderr>:Instructions for updating:
[1,8]<stderr>:Colocations handled automatically by placer.
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,11]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,11]<stderr>:Instructions for updating:
[1,11]<stderr>:Colocations handled automatically by placer.
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,13]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,13]<stderr>:Instructions for updating:
[1,13]<stderr>:Colocations handled automatically by placer.
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,9]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,9]<stderr>:Instructions for updating:
[1,9]<stderr>:Colocations handled automatically by placer.
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,0]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,0]<stderr>:Instructions for updating:
[1,0]<stderr>:Colocations handled automatically by placer.
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,10]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,10]<stderr>:Instructions for updating:
[1,10]<stderr>:Colocations handled automatically by placer.
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,2]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,2]<stderr>:Instructions for updating:
[1,2]<stderr>:Colocations handled automatically by placer.
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,3]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,3]<stderr>:Instructions for updating:
[1,3]<stderr>:Colocations handled automatically by placer.
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,1]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,1]<stderr>:Instructions for updating:
[1,1]<stderr>:Colocations handled automatically by placer.
[1,14]<stderr>:2020-04-12 19:15:43.877087: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,14]<stderr>:2020-04-12 19:15:43.887561: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,14]<stderr>:2020-04-12 19:15:43.888880: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5583c06af1a0 executing computations on platform Host. Devices:
[1,14]<stderr>:2020-04-12 19:15:43.888920: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,12]<stderr>:2020-04-12 19:15:43.954136: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,12]<stderr>:2020-04-12 19:15:43.963616: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,12]<stderr>:2020-04-12 19:15:43.965157: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5568716781a0 executing computations on platform Host. Devices:
[1,12]<stderr>:2020-04-12 19:15:43.965187: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,15]<stderr>:2020-04-12 19:15:43.976616: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,15]<stderr>:2020-04-12 19:15:43.983753: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,15]<stderr>:2020-04-12 19:15:43.984486: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fa182ec1a0 executing computations on platform Host. Devices:
[1,15]<stderr>:2020-04-12 19:15:43.984514: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,13]<stderr>:2020-04-12 19:15:43.991480: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,13]<stderr>:2020-04-12 19:15:43.997564: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,13]<stderr>:2020-04-12 19:15:43.998717: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x563bc679c1a0 executing computations on platform Host. Devices:
[1,13]<stderr>:2020-04-12 19:15:43.998744: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,7]<stderr>:2020-04-12 19:15:44.142483: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,7]<stderr>:2020-04-12 19:15:44.152640: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,7]<stderr>:2020-04-12 19:15:44.154412: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55dad29081a0 executing computations on platform Host. Devices:
[1,7]<stderr>:2020-04-12 19:15:44.154449: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,4]<stderr>:2020-04-12 19:15:44.211166: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,4]<stderr>:2020-04-12 19:15:44.218062: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,4]<stderr>:2020-04-12 19:15:44.219813: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55cb3fe151a0 executing computations on platform Host. Devices:
[1,4]<stderr>:2020-04-12 19:15:44.219843: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,6]<stderr>:2020-04-12 19:15:44.225997: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,6]<stderr>:2020-04-12 19:15:44.233304: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,6]<stderr>:2020-04-12 19:15:44.234014: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a3e99ea1a0 executing computations on platform Host. Devices:
[1,6]<stderr>:2020-04-12 19:15:44.234039: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,5]<stderr>:2020-04-12 19:15:44.292020: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,5]<stderr>:2020-04-12 19:15:44.298612: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,5]<stderr>:2020-04-12 19:15:44.299528: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5637c44c01a0 executing computations on platform Host. Devices:
[1,5]<stderr>:2020-04-12 19:15:44.299552: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,3]<stderr>:2020-04-12 19:15:44.480397: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,3]<stderr>:2020-04-12 19:15:44.490849: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,3]<stderr>:2020-04-12 19:15:44.492374: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558e7f4f6f80 executing computations on platform Host. Devices:
[1,3]<stderr>:2020-04-12 19:15:44.492415: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,2]<stderr>:2020-04-12 19:15:44.524250: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,2]<stderr>:2020-04-12 19:15:44.533048: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,2]<stderr>:2020-04-12 19:15:44.534166: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fa553c36b0 executing computations on platform Host. Devices:
[1,2]<stderr>:2020-04-12 19:15:44.534200: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,1]<stderr>:2020-04-12 19:15:44.536460: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,14]<stderr>:2020-04-12 19:15:44.538625: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,14]<stderr>:2020-04-12 19:15:44.545222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,14]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,14]<stderr>:pciBusID: 0000:00:06.0
[1,14]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,14]<stderr>:2020-04-12 19:15:44.545258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,1]<stderr>:2020-04-12 19:15:44.546719: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,1]<stderr>:2020-04-12 19:15:44.547816: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56539e16f5e0 executing computations on platform Host. Devices:
[1,1]<stderr>:2020-04-12 19:15:44.547844: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,14]<stderr>:2020-04-12 19:15:44.592550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,14]<stderr>:2020-04-12 19:15:44.592579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,14]<stderr>:2020-04-12 19:15:44.592586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,14]<stderr>:2020-04-12 19:15:44.592948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,8]<stderr>:2020-04-12 19:15:44.614589: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,8]<stderr>:2020-04-12 19:15:44.627435: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,8]<stderr>:2020-04-12 19:15:44.628756: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x555dc239d1a0 executing computations on platform Host. Devices:
[1,8]<stderr>:2020-04-12 19:15:44.628805: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,10]<stderr>:2020-04-12 19:15:44.684970: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,10]<stderr>:2020-04-12 19:15:44.694580: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,10]<stderr>:2020-04-12 19:15:44.696160: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5604e5f011a0 executing computations on platform Host. Devices:
[1,10]<stderr>:2020-04-12 19:15:44.696203: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,11]<stderr>:2020-04-12 19:15:44.724888: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,11]<stderr>:2020-04-12 19:15:44.735384: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,11]<stderr>:2020-04-12 19:15:44.736345: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557471d731a0 executing computations on platform Host. Devices:
[1,11]<stderr>:2020-04-12 19:15:44.736374: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,9]<stderr>:2020-04-12 19:15:44.815936: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,9]<stderr>:2020-04-12 19:15:44.823366: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,9]<stderr>:2020-04-12 19:15:44.824592: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fc7d8501a0 executing computations on platform Host. Devices:
[1,9]<stderr>:2020-04-12 19:15:44.824626: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,7]<stderr>:2020-04-12 19:15:44.826056: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-04-12 19:15:44.833489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,7]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,7]<stderr>:pciBusID: 0000:00:07.0
[1,7]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,7]<stderr>:2020-04-12 19:15:44.833531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,7]<stderr>:2020-04-12 19:15:44.880389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,7]<stderr>:2020-04-12 19:15:44.880420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,7]<stderr>:2020-04-12 19:15:44.880430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,7]<stderr>:2020-04-12 19:15:44.880772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,3]<stderr>:2020-04-12 19:15:45.072763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-12 19:15:45.077705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,3]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,3]<stderr>:pciBusID: 0000:00:07.0
[1,3]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,3]<stderr>:2020-04-12 19:15:45.077759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,15]<stderr>:2020-04-12 19:15:45.094147: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-12 19:15:45.099993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,15]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,15]<stderr>:pciBusID: 0000:00:07.0
[1,15]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,15]<stderr>:2020-04-12 19:15:45.100031: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,13]<stderr>:2020-04-12 19:15:45.101901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-12 19:15:45.107260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-12 19:15:45.107635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,13]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,13]<stderr>:pciBusID: 0000:00:05.0
[1,13]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,13]<stderr>:2020-04-12 19:15:45.107666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,12]<stderr>:2020-04-12 19:15:45.112612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,12]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,12]<stderr>:pciBusID: 0000:00:04.0
[1,12]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,12]<stderr>:2020-04-12 19:15:45.112643: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,3]<stderr>:2020-04-12 19:15:45.116256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,3]<stderr>:2020-04-12 19:15:45.116293: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,3]<stderr>:2020-04-12 19:15:45.116303: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,3]<stderr>:2020-04-12 19:15:45.116545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,15]<stderr>:2020-04-12 19:15:45.122383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,15]<stderr>:2020-04-12 19:15:45.122412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,15]<stderr>:2020-04-12 19:15:45.122420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,15]<stderr>:2020-04-12 19:15:45.122661: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14238 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,13]<stderr>:2020-04-12 19:15:45.135523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,13]<stderr>:2020-04-12 19:15:45.135553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,13]<stderr>:2020-04-12 19:15:45.135561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,13]<stderr>:2020-04-12 19:15:45.136007: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14236 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,12]<stderr>:2020-04-12 19:15:45.143113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,12]<stderr>:2020-04-12 19:15:45.143139: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,12]<stderr>:2020-04-12 19:15:45.143144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,12]<stderr>:2020-04-12 19:15:45.143625: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14230 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,8]<stderr>:2020-04-12 19:15:45.201550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-12 19:15:45.207175: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,8]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,8]<stderr>:pciBusID: 0000:00:04.0
[1,8]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,8]<stderr>:2020-04-12 19:15:45.207225: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,8]<stderr>:2020-04-12 19:15:45.358947: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,8]<stderr>:2020-04-12 19:15:45.358987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,8]<stderr>:2020-04-12 19:15:45.358994: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,8]<stderr>:2020-04-12 19:15:45.360103: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,4]<stderr>:2020-04-12 19:15:45.417958: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-12 19:15:45.424790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,4]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,4]<stderr>:pciBusID: 0000:00:04.0
[1,4]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,4]<stderr>:2020-04-12 19:15:45.424831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,6]<stderr>:2020-04-12 19:15:45.427407: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-04-12 19:15:45.430828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-12 19:15:45.431768: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,6]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,6]<stderr>:pciBusID: 0000:00:06.0
[1,6]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,6]<stderr>:2020-04-12 19:15:45.431801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,5]<stderr>:2020-04-12 19:15:45.435983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,5]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,5]<stderr>:pciBusID: 0000:00:05.0
[1,5]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,5]<stderr>:2020-04-12 19:15:45.436019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,4]<stderr>:2020-04-12 19:15:45.448392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,4]<stderr>:2020-04-12 19:15:45.448421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,4]<stderr>:2020-04-12 19:15:45.448429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,4]<stderr>:2020-04-12 19:15:45.448626: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14238 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,6]<stderr>:2020-04-12 19:15:45.457163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,6]<stderr>:2020-04-12 19:15:45.457188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,6]<stderr>:2020-04-12 19:15:45.457194: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,6]<stderr>:2020-04-12 19:15:45.457575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14236 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,5]<stderr>:2020-04-12 19:15:45.463648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,5]<stderr>:2020-04-12 19:15:45.463680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,5]<stderr>:2020-04-12 19:15:45.463688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,5]<stderr>:2020-04-12 19:15:45.464098: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14236 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,2]<stderr>:2020-04-12 19:15:45.621990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-04-12 19:15:45.624188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-04-12 19:15:45.626043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,2]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,2]<stderr>:pciBusID: 0000:00:06.0
[1,2]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,2]<stderr>:2020-04-12 19:15:45.626077: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,1]<stderr>:2020-04-12 19:15:45.629659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,1]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,1]<stderr>:pciBusID: 0000:00:05.0
[1,1]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,1]<stderr>:2020-04-12 19:15:45.629690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,2]<stderr>:2020-04-12 19:15:45.646280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,2]<stderr>:2020-04-12 19:15:45.646310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,2]<stderr>:2020-04-12 19:15:45.646319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,2]<stderr>:2020-04-12 19:15:45.646713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14238 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,1]<stderr>:2020-04-12 19:15:45.648319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,1]<stderr>:2020-04-12 19:15:45.648344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,1]<stderr>:2020-04-12 19:15:45.648351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,1]<stderr>:2020-04-12 19:15:45.648442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14238 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,10]<stderr>:2020-04-12 19:15:45.898205: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-12 19:15:45.904448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-12 19:15:45.904614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,10]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,10]<stderr>:pciBusID: 0000:00:06.0
[1,10]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,10]<stderr>:2020-04-12 19:15:45.904672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,11]<stderr>:2020-04-12 19:15:45.913706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,11]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,11]<stderr>:pciBusID: 0000:00:07.0
[1,11]<stderr>:totalMemory: 14.75GiB freeMemory: 14.64GiB
[1,11]<stderr>:2020-04-12 19:15:45.913752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,0]<stdout>:Model: DenseNet121
[1,0]<stdout>:Batch size: 64
[1,0]<stdout>:Number of GPUs: 16
[1,0]<stderr>:2020-04-12 19:15:45.920030: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,10]<stderr>:2020-04-12 19:15:45.930622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,10]<stderr>:2020-04-12 19:15:45.930659: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,10]<stderr>:2020-04-12 19:15:45.930669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,0]<stderr>:2020-04-12 19:15:45.931367: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,10]<stderr>:2020-04-12 19:15:45.930905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14238 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,0]<stderr>:2020-04-12 19:15:45.932638: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56170704d260 executing computations on platform Host. Devices:
[1,0]<stderr>:2020-04-12 19:15:45.932667: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,11]<stderr>:2020-04-12 19:15:45.935246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,11]<stderr>:2020-04-12 19:15:45.935275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,11]<stderr>:2020-04-12 19:15:45.935282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,11]<stderr>:2020-04-12 19:15:45.936079: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14238 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,9]<stderr>:2020-04-12 19:15:46.078664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-12 19:15:46.418571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,9]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,9]<stderr>:pciBusID: 0000:00:05.0
[1,9]<stderr>:totalMemory: 14.75GiB freeMemory: 14.62GiB
[1,9]<stderr>:2020-04-12 19:15:46.418632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,14]<stderr>:2020-04-12 19:15:46.618474: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,14]<stderr>:2020-04-12 19:15:46.665262: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-12 19:15:46.686672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,9]<stderr>:2020-04-12 19:15:46.686711: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,9]<stderr>:2020-04-12 19:15:46.686718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,9]<stderr>:2020-04-12 19:15:46.687019: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14215 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,14]<stderr>:2020-04-12 19:15:46.766013: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,14]<stderr>:2020-04-12 19:15:46.787820: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5583c5449310 executing computations on platform CUDA. Devices:
[1,14]<stderr>:2020-04-12 19:15:46.787855: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-12 19:15:46.787866: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-12 19:15:46.787883: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-12 19:15:46.787892: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-12 19:15:46.952453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-12 19:15:46.980690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-12 19:15:46.996538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-12 19:15:46.996636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-12 19:15:46.999173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-12 19:15:47.000415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-12 19:15:47.001496: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fa1d086330 executing computations on platform CUDA. Devices:
[1,15]<stderr>:2020-04-12 19:15:47.001529: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-12 19:15:47.001538: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-12 19:15:47.001545: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-12 19:15:47.001552: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-12 19:15:47.009482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-12 19:15:47.012004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-12 19:15:47.014370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-12 19:15:47.031439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-12 19:15:47.033289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-12 19:15:47.033644: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x563bcb5363f0 executing computations on platform CUDA. Devices:
[1,13]<stderr>:2020-04-12 19:15:47.033679: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,13]<stderr>:2020-04-12 19:15:47.033688: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,13]<stderr>:2020-04-12 19:15:47.033695: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,13]<stderr>:2020-04-12 19:15:47.033702: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-12 19:15:47.035144: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x556876411aa0 executing computations on platform CUDA. Devices:
[1,12]<stderr>:2020-04-12 19:15:47.035173: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-12 19:15:47.035180: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-12 19:15:47.035184: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-12 19:15:47.035188: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-12 19:15:47.066021: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-12 19:15:47.085480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-12 19:15:47.158206: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-04-12 19:15:47.167169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-12 19:15:47.167597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,0]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,0]<stderr>:pciBusID: 0000:00:04.0
[1,0]<stderr>:totalMemory: 14.75GiB freeMemory: 14.53GiB
[1,0]<stderr>:2020-04-12 19:15:47.167641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,3]<stderr>:2020-04-12 19:15:47.171482: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-12 19:15:47.193374: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558e83215590 executing computations on platform CUDA. Devices:
[1,3]<stderr>:2020-04-12 19:15:47.193419: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,3]<stderr>:2020-04-12 19:15:47.193430: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,3]<stderr>:2020-04-12 19:15:47.193439: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,3]<stderr>:2020-04-12 19:15:47.193448: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-12 19:15:47.199869: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55dad76a1c50 executing computations on platform CUDA. Devices:
[1,7]<stderr>:2020-04-12 19:15:47.199910: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-12 19:15:47.199917: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-12 19:15:47.199924: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-12 19:15:47.199930: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-12 19:15:47.240421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,0]<stderr>:2020-04-12 19:15:47.240461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,0]<stderr>:2020-04-12 19:15:47.240469: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,0]<stderr>:2020-04-12 19:15:47.240838: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14126 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,4]<stderr>:2020-04-12 19:15:47.359702: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-12 19:15:47.406461: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-12 19:15:47.416002: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-04-12 19:15:47.416729: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-12 19:15:47.429306: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-04-12 19:15:47.437949: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-12 19:15:47.447074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-12 19:15:47.450588: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55cb44baef20 executing computations on platform CUDA. Devices:
[1,4]<stderr>:2020-04-12 19:15:47.450628: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:2020-04-12 19:15:47.450637: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:2020-04-12 19:15:47.450645: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:2020-04-12 19:15:47.450652: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:2020-04-12 19:15:47.455182: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-12 19:15:47.457351: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55a3ee783f30 executing computations on platform CUDA. Devices:
[1,6]<stderr>:2020-04-12 19:15:47.457386: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:2020-04-12 19:15:47.457396: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:2020-04-12 19:15:47.457403: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:2020-04-12 19:15:47.457410: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,5]<stderr>:2020-04-12 19:15:47.458475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-04-12 19:15:47.459719: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5637c9259ab0 executing computations on platform CUDA. Devices:
[1,5]<stderr>:2020-04-12 19:15:47.459747: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,5]<stderr>:2020-04-12 19:15:47.459753: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,5]<stderr>:2020-04-12 19:15:47.459758: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,5]<stderr>:2020-04-12 19:15:47.459762: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-12 19:15:47.469216: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-12 19:15:47.544552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-12 19:15:47.637777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-12 19:15:47.655918: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x555dc7136ce0 executing computations on platform CUDA. Devices:
[1,8]<stderr>:2020-04-12 19:15:47.655955: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-12 19:15:47.655969: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-12 19:15:47.655976: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-12 19:15:47.655983: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-12 19:15:47.720988: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-04-12 19:15:47.724718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-04-12 19:15:47.748690: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-04-12 19:15:47.751695: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-04-12 19:15:47.787648: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-04-12 19:15:47.790705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-04-12 19:15:47.796489: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5653a183df50 executing computations on platform CUDA. Devices:
[1,1]<stderr>:2020-04-12 19:15:47.796528: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-12 19:15:47.796542: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-12 19:15:47.796549: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-12 19:15:47.796555: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-12 19:15:47.798721: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fa590e22b0 executing computations on platform CUDA. Devices:
[1,2]<stderr>:2020-04-12 19:15:47.798756: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-12 19:15:47.798764: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-12 19:15:47.798772: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-12 19:15:47.798779: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,11]<stderr>:2020-04-12 19:15:47.847697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-12 19:15:47.874923: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-12 19:15:47.889553: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-12 19:15:47.897219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-12 19:15:47.924597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-12 19:15:47.932024: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557476b0ce20 executing computations on platform CUDA. Devices:
[1,11]<stderr>:2020-04-12 19:15:47.932060: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,11]<stderr>:2020-04-12 19:15:47.932067: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,11]<stderr>:2020-04-12 19:15:47.932072: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,11]<stderr>:2020-04-12 19:15:47.932076: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-12 19:15:47.935094: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-12 19:15:47.935378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-12 19:15:47.938925: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5604eac9a510 executing computations on platform CUDA. Devices:
[1,10]<stderr>:2020-04-12 19:15:47.938954: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-12 19:15:47.938961: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-12 19:15:47.938966: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-12 19:15:47.938971: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-12 19:15:47.944355: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-12 19:15:47.953380: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-12 19:15:47.954803: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55fc825ea690 executing computations on platform CUDA. Devices:
[1,9]<stderr>:2020-04-12 19:15:47.954831: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-12 19:15:47.954838: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-12 19:15:47.954843: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-12 19:15:47.954848: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-12 19:15:48.026678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-12 19:15:48.044652: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-12 19:15:48.054130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-12 19:15:48.055567: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56170ad6c840 executing computations on platform CUDA. Devices:
[1,0]<stderr>:2020-04-12 19:15:48.055610: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-12 19:15:48.055621: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-12 19:15:48.055629: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-12 19:15:48.055634: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,4]<stderr>:Instructions for updating:
[1,4]<stderr>:Use tf.cast instead.
[1,15]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,15]<stderr>:Instructions for updating:
[1,15]<stderr>:Use tf.cast instead.
[1,12]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,12]<stderr>:Instructions for updating:
[1,12]<stderr>:Use tf.cast instead.
[1,5]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,5]<stderr>:Instructions for updating:
[1,5]<stderr>:Use tf.cast instead.
[1,7]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,7]<stderr>:Instructions for updating:
[1,7]<stderr>:Use tf.cast instead.
[1,14]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,14]<stderr>:Instructions for updating:
[1,14]<stderr>:Use tf.cast instead.
[1,6]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,6]<stderr>:Instructions for updating:
[1,6]<stderr>:Use tf.cast instead.
[1,13]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,13]<stderr>:Instructions for updating:
[1,13]<stderr>:Use tf.cast instead.
[1,15]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,15]<stderr>:Instructions for updating:
[1,15]<stderr>:Use tf.cast instead.
[1,4]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,4]<stderr>:Instructions for updating:
[1,4]<stderr>:Use tf.cast instead.
[1,12]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,12]<stderr>:Instructions for updating:
[1,12]<stderr>:Use tf.cast instead.
[1,7]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,7]<stderr>:Instructions for updating:
[1,7]<stderr>:Use tf.cast instead.
[1,14]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,14]<stderr>:Instructions for updating:
[1,14]<stderr>:Use tf.cast instead.
[1,5]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,5]<stderr>:Instructions for updating:
[1,5]<stderr>:Use tf.cast instead.
[1,1]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,1]<stderr>:Instructions for updating:
[1,1]<stderr>:Use tf.cast instead.
[1,8]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,8]<stderr>:Instructions for updating:
[1,8]<stderr>:Use tf.cast instead.
[1,10]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,10]<stderr>:Instructions for updating:
[1,10]<stderr>:Use tf.cast instead.
[1,6]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,6]<stderr>:Instructions for updating:
[1,6]<stderr>:Use tf.cast instead.
[1,13]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,13]<stderr>:Instructions for updating:
[1,13]<stderr>:Use tf.cast instead.
[1,11]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,11]<stderr>:Instructions for updating:
[1,11]<stderr>:Use tf.cast instead.
[1,9]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,9]<stderr>:Instructions for updating:
[1,9]<stderr>:Use tf.cast instead.
[1,3]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,3]<stderr>:Instructions for updating:
[1,3]<stderr>:Use tf.cast instead.
[1,0]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,0]<stderr>:Instructions for updating:
[1,0]<stderr>:Use tf.cast instead.
[1,1]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,1]<stderr>:Instructions for updating:
[1,1]<stderr>:Use tf.cast instead.
[1,8]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,8]<stderr>:Instructions for updating:
[1,8]<stderr>:Use tf.cast instead.
[1,10]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,10]<stderr>:Instructions for updating:
[1,10]<stderr>:Use tf.cast instead.
[1,11]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,11]<stderr>:Instructions for updating:
[1,11]<stderr>:Use tf.cast instead.
[1,9]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,9]<stderr>:Instructions for updating:
[1,9]<stderr>:Use tf.cast instead.
[1,3]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,3]<stderr>:Instructions for updating:
[1,3]<stderr>:Use tf.cast instead.
[1,0]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,0]<stderr>:Instructions for updating:
[1,0]<stderr>:Use tf.cast instead.
[1,2]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,2]<stderr>:Instructions for updating:
[1,2]<stderr>:Use tf.cast instead.
[1,2]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,2]<stderr>:Instructions for updating:
[1,2]<stderr>:Use tf.cast instead.
[1,0]<stdout>:Running warmup...
[1,15]<stderr>:2020-04-12 19:15:58.553902: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,12]<stderr>:2020-04-12 19:15:58.605239: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,7]<stderr>:2020-04-12 19:15:58.612641: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,14]<stderr>:2020-04-12 19:15:58.622013: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,4]<stderr>:2020-04-12 19:15:58.646821: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,13]<stderr>:2020-04-12 19:15:58.699769: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,6]<stderr>:2020-04-12 19:15:58.702614: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,5]<stderr>:2020-04-12 19:15:58.759779: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,1]<stderr>:2020-04-12 19:15:59.192860: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,3]<stderr>:2020-04-12 19:15:59.193626: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,0]<stderr>:2020-04-12 19:15:59.196230: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,10]<stderr>:2020-04-12 19:15:59.240468: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,8]<stderr>:2020-04-12 19:15:59.254130: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,11]<stderr>:2020-04-12 19:15:59.290691: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,9]<stderr>:2020-04-12 19:15:59.334729: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,2]<stderr>:2020-04-12 19:16:01.703153: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,4]<stderr>:2020-04-12 19:16:01.927751: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.91G (6340745472 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,15]<stderr>:2020-04-12 19:16:01.956363: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.91G (6340807680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,7]<stderr>:2020-04-12 19:16:01.990048: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.92G (6352761600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,13]<stderr>:2020-04-12 19:16:02.013023: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.90G (6338815488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,6]<stderr>:2020-04-12 19:16:02.029043: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.90G (6338815488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,12]<stderr>:2020-04-12 19:16:02.049577: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.90G (6332838656 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,5]<stderr>:2020-04-12 19:16:02.100860: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.90G (6338815488 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,14]<stderr>:2020-04-12 19:16:02.137637: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.92G (6352761600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,1]<stderr>:2020-04-12 19:16:02.617038: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.91G (6340807680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,3]<stderr>:2020-04-12 19:16:02.636374: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.92G (6352761600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,8]<stderr>:2020-04-12 19:16:02.669566: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.92G (6352761600 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,10]<stderr>:2020-04-12 19:16:02.817397: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.91G (6340807680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,11]<stderr>:2020-04-12 19:16:02.907051: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.91G (6340807680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,2]<stderr>:2020-04-12 19:16:05.229644: E tensorflow/stream_executor/cuda/cuda_driver.cc:806] failed to allocate 5.91G (6340807680 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[1,0]<stdout>:Running benchmark...
[1,0]<stdout>:TIME BEFORE ITER #0 is 1586718972.034116
[1,0]<stdout>:TIME AFTER ITER #0 is 1586718972.723624
[1,0]<stdout>:Iter #0: 92.8 img/sec per GPU took 0.689357
[1,0]<stdout>:TIME BEFORE ITER #1 is 1586718972.723698
[1,0]<stdout>:TIME AFTER ITER #1 is 1586718973.422852
[1,0]<stdout>:Iter #1: 91.6 img/sec per GPU took 0.698987
[1,0]<stdout>:TIME BEFORE ITER #2 is 1586718973.422920
[1,0]<stdout>:TIME AFTER ITER #2 is 1586718974.121909
[1,0]<stdout>:Iter #2: 91.6 img/sec per GPU took 0.698844
[1,0]<stdout>:TIME BEFORE ITER #3 is 1586718974.122001
[1,0]<stdout>:TIME AFTER ITER #3 is 1586718974.825499
[1,0]<stdout>:Iter #3: 91.0 img/sec per GPU took 0.703259
[1,0]<stdout>:TIME BEFORE ITER #4 is 1586718974.825594
[1,0]<stdout>:TIME AFTER ITER #4 is 1586718975.530029
[1,0]<stdout>:Iter #4: 90.9 img/sec per GPU took 0.704239
[1,0]<stdout>:TIME BEFORE ITER #5 is 1586718975.530092
[1,0]<stdout>:TIME AFTER ITER #5 is 1586718976.241564
[1,0]<stdout>:Iter #5: 90.0 img/sec per GPU took 0.711317
[1,0]<stdout>:TIME BEFORE ITER #6 is 1586718976.241640
[1,0]<stdout>:TIME AFTER ITER #6 is 1586718976.947370
[1,0]<stdout>:Iter #6: 90.7 img/sec per GPU took 0.705551
[1,0]<stdout>:TIME BEFORE ITER #7 is 1586718976.947440
[1,0]<stdout>:TIME AFTER ITER #7 is 1586718977.655569
[1,0]<stdout>:Iter #7: 90.4 img/sec per GPU took 0.707931
[1,0]<stdout>:TIME BEFORE ITER #8 is 1586718977.655638
[1,0]<stdout>:TIME AFTER ITER #8 is 1586718978.363570
[1,0]<stdout>:Iter #8: 90.4 img/sec per GPU took 0.707740
[1,0]<stdout>:TIME BEFORE ITER #9 is 1586718978.363636
[1,0]<stdout>:TIME AFTER ITER #9 is 1586718979.080417
[1,0]<stdout>:Iter #9: 89.3 img/sec per GPU took 0.716622
[1,0]<stdout>:TIME BEFORE ITER #10 is 1586718979.080520
[1,0]<stdout>:TIME AFTER ITER #10 is 1586718979.798639
[1,0]<stdout>:Iter #10: 89.1 img/sec per GPU took 0.717948
[1,0]<stdout>:TIME BEFORE ITER #11 is 1586718979.798704
[1,0]<stdout>:TIME AFTER ITER #11 is 1586718980.516072
[1,0]<stdout>:Iter #11: 89.2 img/sec per GPU took 0.717187
[1,0]<stdout>:TIME BEFORE ITER #12 is 1586718980.516185
[1,0]<stdout>:TIME AFTER ITER #12 is 1586718981.236097
[1,0]<stdout>:Iter #12: 88.9 img/sec per GPU took 0.719762
[1,0]<stdout>:TIME BEFORE ITER #13 is 1586718981.236168
[1,0]<stdout>:TIME AFTER ITER #13 is 1586718981.958842
[1,0]<stdout>:Iter #13: 88.6 img/sec per GPU took 0.722460
[1,0]<stdout>:TIME BEFORE ITER #14 is 1586718981.958919
[1,0]<stdout>:TIME AFTER ITER #14 is 1586718982.691000
[1,0]<stdout>:Iter #14: 87.4 img/sec per GPU took 0.731903
[1,0]<stdout>:TIME BEFORE ITER #15 is 1586718982.691073
[1,0]<stdout>:TIME AFTER ITER #15 is 1586718983.411715
[1,0]<stdout>:Iter #15: 88.8 img/sec per GPU took 0.720489
[1,0]<stdout>:TIME BEFORE ITER #16 is 1586718983.411786
[1,0]<stdout>:TIME AFTER ITER #16 is 1586718984.135870
[1,0]<stdout>:Iter #16: 88.4 img/sec per GPU took 0.723929
[1,0]<stdout>:TIME BEFORE ITER #17 is 1586718984.135935
[1,0]<stdout>:TIME AFTER ITER #17 is 1586718984.868116
[1,0]<stdout>:Iter #17: 87.4 img/sec per GPU took 0.731998
[1,0]<stdout>:TIME BEFORE ITER #18 is 1586718984.868180
[1,0]<stdout>:TIME AFTER ITER #18 is 1586718985.598799
[1,0]<stdout>:Iter #18: 87.6 img/sec per GPU took 0.730476
[1,0]<stdout>:TIME BEFORE ITER #19 is 1586718985.598870
[1,0]<stdout>:TIME AFTER ITER #19 is 1586718986.334328
[1,0]<stdout>:Iter #19: 87.0 img/sec per GPU took 0.735276
[1,0]<stdout>:TIME BEFORE ITER #20 is 1586718986.334395
[1,0]<stdout>:TIME AFTER ITER #20 is 1586718987.066294
[1,0]<stdout>:Iter #20: 87.5 img/sec per GPU took 0.731682
[1,0]<stdout>:TIME BEFORE ITER #21 is 1586718987.066378
[1,0]<stdout>:TIME AFTER ITER #21 is 1586718987.797565
[1,0]<stdout>:Iter #21: 87.6 img/sec per GPU took 0.730970
[1,0]<stdout>:TIME BEFORE ITER #22 is 1586718987.797638
[1,0]<stdout>:TIME AFTER ITER #22 is 1586718988.542153
[1,0]<stdout>:Iter #22: 86.0 img/sec per GPU took 0.744336
[1,0]<stdout>:TIME BEFORE ITER #23 is 1586718988.542247
[1,0]<stdout>:TIME AFTER ITER #23 is 1586718989.280252
[1,0]<stdout>:Iter #23: 86.7 img/sec per GPU took 0.737818
[1,0]<stdout>:TIME BEFORE ITER #24 is 1586718989.280346
[1,0]<stdout>:TIME AFTER ITER #24 is 1586718990.027334
[1,0]<stdout>:Iter #24: 85.7 img/sec per GPU took 0.746799
[1,0]<stdout>:TIME BEFORE ITER #25 is 1586718990.027399
[1,0]<stdout>:TIME AFTER ITER #25 is 1586718990.764513
[1,0]<stdout>:Iter #25: 86.8 img/sec per GPU took 0.736951
[1,0]<stdout>:TIME BEFORE ITER #26 is 1586718990.764587
[1,0]<stdout>:TIME AFTER ITER #26 is 1586718991.507482
[1,0]<stdout>:Iter #26: 86.2 img/sec per GPU took 0.742725
[1,0]<stdout>:TIME BEFORE ITER #27 is 1586718991.507569
[1,0]<stdout>:TIME AFTER ITER #27 is 1586718992.262394
[1,0]<stdout>:Iter #27: 84.8 img/sec per GPU took 0.754655
[1,0]<stdout>:TIME BEFORE ITER #28 is 1586718992.262468
[1,0]<stdout>:TIME AFTER ITER #28 is 1586718993.004863
[1,0]<stdout>:Iter #28: 86.2 img/sec per GPU took 0.742203
[1,0]<stdout>:TIME BEFORE ITER #29 is 1586718993.004929
[1,0]<stdout>:TIME AFTER ITER #29 is 1586718993.756238
[1,0]<stdout>:Iter #29: 85.2 img/sec per GPU took 0.751138
[1,0]<stdout>:TIME BEFORE ITER #30 is 1586718993.756311
[1,0]<stdout>:TIME AFTER ITER #30 is 1586718994.508956
[1,0]<stdout>:Iter #30: 85.1 img/sec per GPU took 0.752482
[1,0]<stdout>:TIME BEFORE ITER #31 is 1586718994.509031
[1,0]<stdout>:TIME AFTER ITER #31 is 1586718995.258259
[1,0]<stdout>:Iter #31: 85.4 img/sec per GPU took 0.749067
[1,0]<stdout>:TIME BEFORE ITER #32 is 1586718995.258341
[1,0]<stdout>:TIME AFTER ITER #32 is 1586718996.014283
[1,0]<stdout>:Iter #32: 84.7 img/sec per GPU took 0.755429
[1,0]<stdout>:TIME BEFORE ITER #33 is 1586718996.014376
[1,0]<stdout>:TIME AFTER ITER #33 is 1586718996.759881
[1,0]<stdout>:Iter #33: 85.9 img/sec per GPU took 0.745214
[1,0]<stdout>:TIME BEFORE ITER #34 is 1586718996.759993
[1,0]<stdout>:TIME AFTER ITER #34 is 1586718997.510697
[1,0]<stdout>:Iter #34: 85.3 img/sec per GPU took 0.750437
[1,0]<stdout>:TIME BEFORE ITER #35 is 1586718997.510790
[1,0]<stdout>:TIME AFTER ITER #35 is 1586718998.264946
[1,0]<stdout>:Iter #35: 84.9 img/sec per GPU took 0.753918
[1,0]<stdout>:TIME BEFORE ITER #36 is 1586718998.265058
[1,0]<stdout>:TIME AFTER ITER #36 is 1586718999.014831
[1,0]<stdout>:Iter #36: 85.4 img/sec per GPU took 0.749533
[1,0]<stdout>:TIME BEFORE ITER #37 is 1586718999.014913
[1,0]<stdout>:TIME AFTER ITER #37 is 1586718999.764054
[1,0]<stdout>:Iter #37: 85.5 img/sec per GPU took 0.748938
[1,0]<stdout>:TIME BEFORE ITER #38 is 1586718999.764128
[1,0]<stdout>:TIME AFTER ITER #38 is 1586719000.507000
[1,0]<stdout>:Iter #38: 86.2 img/sec per GPU took 0.742585
[1,0]<stdout>:TIME BEFORE ITER #39 is 1586719000.507087
[1,0]<stdout>:TIME AFTER ITER #39 is 1586719001.251246
[1,0]<stdout>:Iter #39: 86.0 img/sec per GPU took 0.743979
[1,0]<stdout>:TIME BEFORE ITER #40 is 1586719001.251315
[1,0]<stdout>:TIME AFTER ITER #40 is 1586719001.982932
[1,0]<stdout>:Iter #40: 87.5 img/sec per GPU took 0.731472
[1,0]<stdout>:TIME BEFORE ITER #41 is 1586719001.983009
[1,0]<stdout>:TIME AFTER ITER #41 is 1586719002.727633
[1,0]<stdout>:Iter #41: 86.0 img/sec per GPU took 0.744438
[1,0]<stdout>:TIME BEFORE ITER #42 is 1586719002.727695
[1,0]<stdout>:TIME AFTER ITER #42 is 1586719003.465484
[1,0]<stdout>:Iter #42: 86.8 img/sec per GPU took 0.737627
[1,0]<stdout>:TIME BEFORE ITER #43 is 1586719003.465557
[1,0]<stdout>:TIME AFTER ITER #43 is 1586719004.193607
[1,0]<stdout>:Iter #43: 87.9 img/sec per GPU took 0.727896
[1,0]<stdout>:TIME BEFORE ITER #44 is 1586719004.193704
[1,0]<stdout>:TIME AFTER ITER #44 is 1586719004.922083
[1,0]<stdout>:Iter #44: 87.9 img/sec per GPU took 0.728225
[1,0]<stdout>:TIME BEFORE ITER #45 is 1586719004.922154
[1,0]<stdout>:TIME AFTER ITER #45 is 1586719005.647611
[1,0]<stdout>:Iter #45: 88.2 img/sec per GPU took 0.725311
[1,0]<stdout>:TIME BEFORE ITER #46 is 1586719005.647672
[1,0]<stdout>:TIME AFTER ITER #46 is 1586719006.374544
[1,0]<stdout>:Iter #46: 88.1 img/sec per GPU took 0.726698
[1,0]<stdout>:TIME BEFORE ITER #47 is 1586719006.374637
[1,0]<stdout>:TIME AFTER ITER #47 is 1586719007.107107
[1,0]<stdout>:Iter #47: 87.4 img/sec per GPU took 0.732275
[1,0]<stdout>:TIME BEFORE ITER #48 is 1586719007.107175
[1,0]<stdout>:TIME AFTER ITER #48 is 1586719007.827619
[1,0]<stdout>:Iter #48: 88.9 img/sec per GPU took 0.720275
[1,0]<stdout>:TIME BEFORE ITER #49 is 1586719007.827689
[1,0]<stdout>:TIME AFTER ITER #49 is 1586719008.560843
[1,0]<stdout>:Iter #49: 87.3 img/sec per GPU took 0.733003
[1,0]<stdout>:TIME BEFORE ITER #50 is 1586719008.560912
[1,0]<stdout>:TIME AFTER ITER #50 is 1586719009.280289
[1,0]<stdout>:Iter #50: 89.0 img/sec per GPU took 0.719225
[1,0]<stdout>:TIME BEFORE ITER #51 is 1586719009.280363
[1,0]<stdout>:TIME AFTER ITER #51 is 1586719010.001628
[1,0]<stdout>:Iter #51: 88.8 img/sec per GPU took 0.721113
[1,0]<stdout>:TIME BEFORE ITER #52 is 1586719010.001698
[1,0]<stdout>:TIME AFTER ITER #52 is 1586719010.718692
[1,0]<stdout>:Iter #52: 89.3 img/sec per GPU took 0.716812
[1,0]<stdout>:TIME BEFORE ITER #53 is 1586719010.718760
[1,0]<stdout>:TIME AFTER ITER #53 is 1586719011.442108
[1,0]<stdout>:Iter #53: 88.5 img/sec per GPU took 0.723185
[1,0]<stdout>:TIME BEFORE ITER #54 is 1586719011.442186
[1,0]<stdout>:TIME AFTER ITER #54 is 1586719012.157470
[1,0]<stdout>:Iter #54: 89.5 img/sec per GPU took 0.715138
[1,0]<stdout>:TIME BEFORE ITER #55 is 1586719012.157548
[1,0]<stdout>:TIME AFTER ITER #55 is 1586719012.874169
[1,0]<stdout>:Iter #55: 89.3 img/sec per GPU took 0.716470
[1,0]<stdout>:TIME BEFORE ITER #56 is 1586719012.874232
[1,0]<stdout>:TIME AFTER ITER #56 is 1586719013.588359
[1,0]<stdout>:Iter #56: 89.6 img/sec per GPU took 0.713916
[1,0]<stdout>:TIME BEFORE ITER #57 is 1586719013.588423
[1,0]<stdout>:TIME AFTER ITER #57 is 1586719014.306755
[1,0]<stdout>:Iter #57: 89.1 img/sec per GPU took 0.718138
[1,0]<stdout>:TIME BEFORE ITER #58 is 1586719014.306823
[1,0]<stdout>:TIME AFTER ITER #58 is 1586719015.016955
[1,0]<stdout>:Iter #58: 90.1 img/sec per GPU took 0.709939
[1,0]<stdout>:TIME BEFORE ITER #59 is 1586719015.017075
[1,0]<stdout>:TIME AFTER ITER #59 is 1586719015.728308
[1,0]<stdout>:Iter #59: 90.0 img/sec per GPU took 0.710980
[1,0]<stdout>:TIME BEFORE ITER #60 is 1586719015.728382
[1,0]<stdout>:TIME AFTER ITER #60 is 1586719016.441342
[1,0]<stdout>:Iter #60: 89.8 img/sec per GPU took 0.712750
[1,0]<stdout>:TIME BEFORE ITER #61 is 1586719016.441420
[1,0]<stdout>:TIME AFTER ITER #61 is 1586719017.153944
[1,0]<stdout>:Iter #61: 89.8 img/sec per GPU took 0.712331
[1,0]<stdout>:TIME BEFORE ITER #62 is 1586719017.154011
[1,0]<stdout>:TIME AFTER ITER #62 is 1586719017.863730
[1,0]<stdout>:Iter #62: 90.2 img/sec per GPU took 0.709564
[1,0]<stdout>:TIME BEFORE ITER #63 is 1586719017.863790
[1,0]<stdout>:TIME AFTER ITER #63 is 1586719018.568758
[1,0]<stdout>:Iter #63: 90.8 img/sec per GPU took 0.704829
[1,0]<stdout>:TIME BEFORE ITER #64 is 1586719018.568821
[1,0]<stdout>:TIME AFTER ITER #64 is 1586719019.281395
[1,0]<stdout>:Iter #64: 89.8 img/sec per GPU took 0.712432
[1,0]<stdout>:TIME BEFORE ITER #65 is 1586719019.281460
[1,0]<stdout>:TIME AFTER ITER #65 is 1586719019.987680
[1,0]<stdout>:Iter #65: 90.6 img/sec per GPU took 0.706066
[1,0]<stdout>:TIME BEFORE ITER #66 is 1586719019.987749
[1,0]<stdout>:TIME AFTER ITER #66 is 1586719020.696494
[1,0]<stdout>:Iter #66: 90.3 img/sec per GPU took 0.708603
[1,0]<stdout>:TIME BEFORE ITER #67 is 1586719020.696587
[1,0]<stdout>:TIME AFTER ITER #67 is 1586719021.403000
[1,0]<stdout>:Iter #67: 90.6 img/sec per GPU took 0.706220
[1,0]<stdout>:TIME BEFORE ITER #68 is 1586719021.403076
[1,0]<stdout>:TIME AFTER ITER #68 is 1586719022.111158
[1,0]<stdout>:Iter #68: 90.4 img/sec per GPU took 0.707918
[1,0]<stdout>:TIME BEFORE ITER #69 is 1586719022.111226
[1,0]<stdout>:TIME AFTER ITER #69 is 1586719022.813282
[1,0]<stdout>:Iter #69: 91.2 img/sec per GPU took 0.701881
[1,0]<stdout>:TIME BEFORE ITER #70 is 1586719022.813359
[1,0]<stdout>:TIME AFTER ITER #70 is 1586719023.511978
[1,0]<stdout>:Iter #70: 91.6 img/sec per GPU took 0.698425
[1,0]<stdout>:TIME BEFORE ITER #71 is 1586719023.512060
[1,0]<stdout>:TIME AFTER ITER #71 is 1586719024.217200
[1,0]<stdout>:Iter #71: 90.8 img/sec per GPU took 0.704958
[1,0]<stdout>:TIME BEFORE ITER #72 is 1586719024.217280
[1,0]<stdout>:TIME AFTER ITER #72 is 1586719024.918546
[1,0]<stdout>:Iter #72: 91.3 img/sec per GPU took 0.701058
[1,0]<stdout>:TIME BEFORE ITER #73 is 1586719024.918646
[1,0]<stdout>:TIME AFTER ITER #73 is 1586719025.614967
[1,0]<stdout>:Iter #73: 91.9 img/sec per GPU took 0.696103
[1,0]<stdout>:TIME BEFORE ITER #74 is 1586719025.615054
[1,0]<stdout>:TIME AFTER ITER #74 is 1586719026.312472
[1,0]<stdout>:Iter #74: 91.8 img/sec per GPU took 0.697209
[1,0]<stdout>:TIME BEFORE ITER #75 is 1586719026.312562
[1,0]<stdout>:TIME AFTER ITER #75 is 1586719027.009385
[1,0]<stdout>:Iter #75: 91.9 img/sec per GPU took 0.696660
[1,0]<stdout>:TIME BEFORE ITER #76 is 1586719027.009456
[1,0]<stdout>:TIME AFTER ITER #76 is 1586719027.707186
[1,0]<stdout>:Iter #76: 91.7 img/sec per GPU took 0.697556
[1,0]<stdout>:TIME BEFORE ITER #77 is 1586719027.707253
[1,0]<stdout>:TIME AFTER ITER #77 is 1586719028.402087
[1,0]<stdout>:Iter #77: 92.1 img/sec per GPU took 0.694680
[1,0]<stdout>:TIME BEFORE ITER #78 is 1586719028.402156
[1,0]<stdout>:TIME AFTER ITER #78 is 1586719029.098432
[1,0]<stdout>:Iter #78: 91.9 img/sec per GPU took 0.696128
[1,0]<stdout>:TIME BEFORE ITER #79 is 1586719029.098500
[1,0]<stdout>:TIME AFTER ITER #79 is 1586719029.791001
[1,0]<stdout>:Iter #79: 92.4 img/sec per GPU took 0.692302
[1,0]<stdout>:TIME BEFORE ITER #80 is 1586719029.791083
[1,0]<stdout>:TIME AFTER ITER #80 is 1586719030.481699
[1,0]<stdout>:Iter #80: 92.7 img/sec per GPU took 0.690433
[1,0]<stdout>:TIME BEFORE ITER #81 is 1586719030.481782
[1,0]<stdout>:TIME AFTER ITER #81 is 1586719031.171123
[1,0]<stdout>:Iter #81: 92.9 img/sec per GPU took 0.689154
[1,0]<stdout>:TIME BEFORE ITER #82 is 1586719031.171209
[1,0]<stdout>:TIME AFTER ITER #82 is 1586719031.860260
[1,0]<stdout>:Iter #82: 92.9 img/sec per GPU took 0.688876
[1,0]<stdout>:TIME BEFORE ITER #83 is 1586719031.860342
[1,0]<stdout>:TIME AFTER ITER #83 is 1586719032.549730
[1,0]<stdout>:Iter #83: 92.9 img/sec per GPU took 0.689163
[1,0]<stdout>:TIME BEFORE ITER #84 is 1586719032.549798
[1,0]<stdout>:TIME AFTER ITER #84 is 1586719033.234402
[1,0]<stdout>:Iter #84: 93.5 img/sec per GPU took 0.684396
[1,0]<stdout>:TIME BEFORE ITER #85 is 1586719033.234474
[1,0]<stdout>:TIME AFTER ITER #85 is 1586719033.923004
[1,0]<stdout>:Iter #85: 93.0 img/sec per GPU took 0.688359
[1,0]<stdout>:TIME BEFORE ITER #86 is 1586719033.923086
[1,0]<stdout>:TIME AFTER ITER #86 is 1586719034.610584
[1,0]<stdout>:Iter #86: 93.1 img/sec per GPU took 0.687343
[1,0]<stdout>:TIME BEFORE ITER #87 is 1586719034.610642
[1,0]<stdout>:TIME AFTER ITER #87 is 1586719035.297787
[1,0]<stdout>:Iter #87: 93.2 img/sec per GPU took 0.686993
[1,0]<stdout>:TIME BEFORE ITER #88 is 1586719035.297846
[1,0]<stdout>:TIME AFTER ITER #88 is 1586719035.991391
[1,0]<stdout>:Iter #88: 92.3 img/sec per GPU took 0.693402
[1,0]<stdout>:TIME BEFORE ITER #89 is 1586719035.991457
[1,0]<stdout>:TIME AFTER ITER #89 is 1586719036.676385
[1,0]<stdout>:Iter #89: 93.5 img/sec per GPU took 0.684727
[1,0]<stdout>:TIME BEFORE ITER #90 is 1586719036.676452
[1,0]<stdout>:TIME AFTER ITER #90 is 1586719037.375351
[1,0]<stdout>:Iter #90: 91.6 img/sec per GPU took 0.698739
[1,0]<stdout>:TIME BEFORE ITER #91 is 1586719037.375416
[1,0]<stdout>:TIME AFTER ITER #91 is 1586719038.061148
[1,0]<stdout>:Iter #91: 93.4 img/sec per GPU took 0.685587
[1,0]<stdout>:TIME BEFORE ITER #92 is 1586719038.061226
[1,0]<stdout>:TIME AFTER ITER #92 is 1586719038.756138
[1,0]<stdout>:Iter #92: 92.1 img/sec per GPU took 0.694717
[1,0]<stdout>:TIME BEFORE ITER #93 is 1586719038.756204
[1,0]<stdout>:TIME AFTER ITER #93 is 1586719039.444382
[1,0]<stdout>:Iter #93: 93.0 img/sec per GPU took 0.688038
[1,0]<stdout>:TIME BEFORE ITER #94 is 1586719039.444455
[1,0]<stdout>:TIME AFTER ITER #94 is 1586719040.136373
[1,0]<stdout>:Iter #94: 92.5 img/sec per GPU took 0.691706
[1,0]<stdout>:TIME BEFORE ITER #95 is 1586719040.136458
[1,0]<stdout>:TIME AFTER ITER #95 is 1586719040.827116
[1,0]<stdout>:Iter #95: 92.7 img/sec per GPU took 0.690438
[1,0]<stdout>:TIME BEFORE ITER #96 is 1586719040.827196
[1,0]<stdout>:TIME AFTER ITER #96 is 1586719041.519087
[1,0]<stdout>:Iter #96: 92.5 img/sec per GPU took 0.691700
[1,0]<stdout>:TIME BEFORE ITER #97 is 1586719041.519162
[1,0]<stdout>:TIME AFTER ITER #97 is 1586719042.205958
[1,0]<stdout>:Iter #97: 93.2 img/sec per GPU took 0.686595
[1,0]<stdout>:TIME BEFORE ITER #98 is 1586719042.206038
[1,0]<stdout>:TIME AFTER ITER #98 is 1586719042.894406
[1,0]<stdout>:Iter #98: 93.0 img/sec per GPU took 0.688209
[1,0]<stdout>:TIME BEFORE ITER #99 is 1586719042.894475
[1,0]<stdout>:TIME AFTER ITER #99 is 1586719043.586851
[1,0]<stdout>:Iter #99: 92.5 img/sec per GPU took 0.692187
[1,0]<stdout>:TIME BEFORE ITER #100 is 1586719043.586926
[1,0]<stdout>:TIME AFTER ITER #100 is 1586719044.280340
[1,0]<stdout>:Iter #100: 92.3 img/sec per GPU took 0.693243
[1,0]<stdout>:TIME BEFORE ITER #101 is 1586719044.280405
[1,0]<stdout>:TIME AFTER ITER #101 is 1586719044.970162
[1,0]<stdout>:Iter #101: 92.8 img/sec per GPU took 0.689610
[1,0]<stdout>:TIME BEFORE ITER #102 is 1586719044.970234
[1,0]<stdout>:TIME AFTER ITER #102 is 1586719045.660102
[1,0]<stdout>:Iter #102: 92.8 img/sec per GPU took 0.689692
[1,0]<stdout>:TIME BEFORE ITER #103 is 1586719045.660169
[1,0]<stdout>:TIME AFTER ITER #103 is 1586719046.352844
[1,0]<stdout>:Iter #103: 92.4 img/sec per GPU took 0.692517
[1,0]<stdout>:TIME BEFORE ITER #104 is 1586719046.352926
[1,0]<stdout>:TIME AFTER ITER #104 is 1586719047.044865
[1,0]<stdout>:Iter #104: 92.5 img/sec per GPU took 0.691777
[1,0]<stdout>:TIME BEFORE ITER #105 is 1586719047.044948
[1,0]<stdout>:TIME AFTER ITER #105 is 1586719047.737937
[1,0]<stdout>:Iter #105: 92.4 img/sec per GPU took 0.692829
[1,0]<stdout>:TIME BEFORE ITER #106 is 1586719047.738012
[1,0]<stdout>:TIME AFTER ITER #106 is 1586719048.430812
[1,0]<stdout>:Iter #106: 92.4 img/sec per GPU took 0.692625
[1,0]<stdout>:TIME BEFORE ITER #107 is 1586719048.430878
[1,0]<stdout>:TIME AFTER ITER #107 is 1586719049.130611
[1,0]<stdout>:Iter #107: 91.5 img/sec per GPU took 0.699583
[1,0]<stdout>:TIME BEFORE ITER #108 is 1586719049.130680
[1,0]<stdout>:TIME AFTER ITER #108 is 1586719049.824627
[1,0]<stdout>:Iter #108: 92.3 img/sec per GPU took 0.693749
[1,0]<stdout>:TIME BEFORE ITER #109 is 1586719049.824718
[1,0]<stdout>:TIME AFTER ITER #109 is 1586719050.523332
[1,0]<stdout>:Iter #109: 91.6 img/sec per GPU took 0.698363
[1,0]<stdout>:TIME BEFORE ITER #110 is 1586719050.523403
[1,0]<stdout>:TIME AFTER ITER #110 is 1586719051.216582
[1,0]<stdout>:Iter #110: 92.3 img/sec per GPU took 0.693021
[1,0]<stdout>:TIME BEFORE ITER #111 is 1586719051.216664
[1,0]<stdout>:TIME AFTER ITER #111 is 1586719051.910836
[1,0]<stdout>:Iter #111: 92.2 img/sec per GPU took 0.694003
[1,0]<stdout>:TIME BEFORE ITER #112 is 1586719051.910899
[1,0]<stdout>:TIME AFTER ITER #112 is 1586719052.607503
[1,0]<stdout>:Iter #112: 91.9 img/sec per GPU took 0.696459
[1,0]<stdout>:TIME BEFORE ITER #113 is 1586719052.607583
[1,0]<stdout>:TIME AFTER ITER #113 is 1586719053.302335
[1,0]<stdout>:Iter #113: 92.1 img/sec per GPU took 0.694609
[1,0]<stdout>:TIME BEFORE ITER #114 is 1586719053.302404
[1,0]<stdout>:TIME AFTER ITER #114 is 1586719053.996068
[1,0]<stdout>:Iter #114: 92.3 img/sec per GPU took 0.693460
[1,0]<stdout>:TIME BEFORE ITER #115 is 1586719053.996164
[1,0]<stdout>:TIME AFTER ITER #115 is 1586719054.698135
[1,0]<stdout>:Iter #115: 91.2 img/sec per GPU took 0.701722
[1,0]<stdout>:TIME BEFORE ITER #116 is 1586719054.698233
[1,0]<stdout>:TIME AFTER ITER #116 is 1586719055.392067
[1,0]<stdout>:Iter #116: 92.3 img/sec per GPU took 0.693610
[1,0]<stdout>:TIME BEFORE ITER #117 is 1586719055.392135
[1,0]<stdout>:TIME AFTER ITER #117 is 1586719056.091218
[1,0]<stdout>:Iter #117: 91.6 img/sec per GPU took 0.698936
[1,0]<stdout>:TIME BEFORE ITER #118 is 1586719056.091282
[1,0]<stdout>:TIME AFTER ITER #118 is 1586719056.788254
[1,0]<stdout>:Iter #118: 91.8 img/sec per GPU took 0.696796
[1,0]<stdout>:TIME BEFORE ITER #119 is 1586719056.788315
[1,0]<stdout>:TIME AFTER ITER #119 is 1586719057.490391
[1,0]<stdout>:Iter #119: 91.2 img/sec per GPU took 0.701906
[1,0]<stdout>:TIME BEFORE ITER #120 is 1586719057.490475
[1,0]<stdout>:TIME AFTER ITER #120 is 1586719058.197331
[1,0]<stdout>:Iter #120: 90.6 img/sec per GPU took 0.706649
[1,0]<stdout>:TIME BEFORE ITER #121 is 1586719058.197404
[1,0]<stdout>:TIME AFTER ITER #121 is 1586719058.898226
[1,0]<stdout>:Iter #121: 91.3 img/sec per GPU took 0.700648
[1,0]<stdout>:TIME BEFORE ITER #122 is 1586719058.898298
[1,0]<stdout>:TIME AFTER ITER #122 is 1586719059.602789
[1,0]<stdout>:Iter #122: 90.9 img/sec per GPU took 0.704324
[1,0]<stdout>:TIME BEFORE ITER #123 is 1586719059.602865
[1,0]<stdout>:TIME AFTER ITER #123 is 1586719060.304023
[1,0]<stdout>:Iter #123: 91.3 img/sec per GPU took 0.700975
[1,0]<stdout>:TIME BEFORE ITER #124 is 1586719060.304092
[1,0]<stdout>:TIME AFTER ITER #124 is 1586719061.003665
[1,0]<stdout>:Iter #124: 91.5 img/sec per GPU took 0.699366
[1,0]<stdout>:TIME BEFORE ITER #125 is 1586719061.003727
[1,0]<stdout>:TIME AFTER ITER #125 is 1586719061.704357
[1,0]<stdout>:Iter #125: 91.4 img/sec per GPU took 0.700435
[1,0]<stdout>:TIME BEFORE ITER #126 is 1586719061.704424
[1,0]<stdout>:TIME AFTER ITER #126 is 1586719062.403392
[1,0]<stdout>:Iter #126: 91.6 img/sec per GPU took 0.698777
[1,0]<stdout>:TIME BEFORE ITER #127 is 1586719062.403462
[1,0]<stdout>:TIME AFTER ITER #127 is 1586719063.113305
[1,0]<stdout>:Iter #127: 90.2 img/sec per GPU took 0.709681
[1,0]<stdout>:TIME BEFORE ITER #128 is 1586719063.113391
[1,0]<stdout>:TIME AFTER ITER #128 is 1586719063.817690
[1,0]<stdout>:Iter #128: 90.9 img/sec per GPU took 0.704136
[1,0]<stdout>:TIME BEFORE ITER #129 is 1586719063.817772
[1,0]<stdout>:TIME AFTER ITER #129 is 1586719064.519234
[1,0]<stdout>:Iter #129: 91.3 img/sec per GPU took 0.701279
[1,0]<stdout>:TIME BEFORE ITER #130 is 1586719064.519303
[1,0]<stdout>:TIME AFTER ITER #130 is 1586719065.225141
[1,0]<stdout>:Iter #130: 90.7 img/sec per GPU took 0.705670
[1,0]<stdout>:TIME BEFORE ITER #131 is 1586719065.225212
[1,0]<stdout>:TIME AFTER ITER #131 is 1586719065.930416
[1,0]<stdout>:Iter #131: 90.8 img/sec per GPU took 0.705058
[1,0]<stdout>:TIME BEFORE ITER #132 is 1586719065.930502
[1,0]<stdout>:TIME AFTER ITER #132 is 1586719066.639015
[1,0]<stdout>:Iter #132: 90.4 img/sec per GPU took 0.708316
[1,0]<stdout>:TIME BEFORE ITER #133 is 1586719066.639084
[1,0]<stdout>:TIME AFTER ITER #133 is 1586719067.347423
[1,0]<stdout>:Iter #133: 90.4 img/sec per GPU took 0.708167
[1,0]<stdout>:TIME BEFORE ITER #134 is 1586719067.347489
[1,0]<stdout>:TIME AFTER ITER #134 is 1586719068.049586
[1,0]<stdout>:Iter #134: 91.2 img/sec per GPU took 0.701904
[1,0]<stdout>:TIME BEFORE ITER #135 is 1586719068.049656
[1,0]<stdout>:TIME AFTER ITER #135 is 1586719068.756516
[1,0]<stdout>:Iter #135: 90.6 img/sec per GPU took 0.706694
[1,0]<stdout>:TIME BEFORE ITER #136 is 1586719068.756587
[1,0]<stdout>:TIME AFTER ITER #136 is 1586719069.466006
[1,0]<stdout>:Iter #136: 90.2 img/sec per GPU took 0.709264
[1,0]<stdout>:TIME BEFORE ITER #137 is 1586719069.466069
[1,0]<stdout>:TIME AFTER ITER #137 is 1586719070.176486
[1,0]<stdout>:Iter #137: 90.1 img/sec per GPU took 0.710264
[1,0]<stdout>:TIME BEFORE ITER #138 is 1586719070.176584
[1,0]<stdout>:TIME AFTER ITER #138 is 1586719070.886062
[1,0]<stdout>:Iter #138: 90.2 img/sec per GPU took 0.709311
[1,0]<stdout>:TIME BEFORE ITER #139 is 1586719070.886132
[1,0]<stdout>:TIME AFTER ITER #139 is 1586719071.596269
[1,0]<stdout>:Iter #139: 90.1 img/sec per GPU took 0.709976
[1,0]<stdout>:TIME BEFORE ITER #140 is 1586719071.596350
[1,0]<stdout>:TIME AFTER ITER #140 is 1586719072.301294
[1,0]<stdout>:Iter #140: 90.8 img/sec per GPU took 0.704742
[1,0]<stdout>:TIME BEFORE ITER #141 is 1586719072.301371
[1,0]<stdout>:TIME AFTER ITER #141 is 1586719073.014286
[1,0]<stdout>:Iter #141: 89.8 img/sec per GPU took 0.712711
[1,0]<stdout>:TIME BEFORE ITER #142 is 1586719073.014383
[1,0]<stdout>:TIME AFTER ITER #142 is 1586719073.723726
[1,0]<stdout>:Iter #142: 90.2 img/sec per GPU took 0.709152
[1,0]<stdout>:TIME BEFORE ITER #143 is 1586719073.723798
[1,0]<stdout>:TIME AFTER ITER #143 is 1586719074.437147
[1,0]<stdout>:Iter #143: 89.7 img/sec per GPU took 0.713186
[1,0]<stdout>:TIME BEFORE ITER #144 is 1586719074.437212
[1,0]<stdout>:TIME AFTER ITER #144 is 1586719075.147264
[1,0]<stdout>:Iter #144: 90.2 img/sec per GPU took 0.709889
[1,0]<stdout>:TIME BEFORE ITER #145 is 1586719075.147346
[1,0]<stdout>:TIME AFTER ITER #145 is 1586719075.859140
[1,0]<stdout>:Iter #145: 89.9 img/sec per GPU took 0.711618
[1,0]<stdout>:TIME BEFORE ITER #146 is 1586719075.859221
[1,0]<stdout>:TIME AFTER ITER #146 is 1586719076.563886
[1,0]<stdout>:Iter #146: 90.9 img/sec per GPU took 0.704444
[1,0]<stdout>:TIME BEFORE ITER #147 is 1586719076.563972
[1,0]<stdout>:TIME AFTER ITER #147 is 1586719077.277066
[1,0]<stdout>:Iter #147: 89.8 img/sec per GPU took 0.712892
[1,0]<stdout>:TIME BEFORE ITER #148 is 1586719077.277137
[1,0]<stdout>:TIME AFTER ITER #148 is 1586719077.985752
[1,0]<stdout>:Iter #148: 90.3 img/sec per GPU took 0.708456
[1,0]<stdout>:TIME BEFORE ITER #149 is 1586719077.985819
[1,0]<stdout>:TIME AFTER ITER #149 is 1586719078.695847
[1,0]<stdout>:Iter #149: 90.2 img/sec per GPU took 0.709893
[1,0]<stdout>:TIME BEFORE ITER #150 is 1586719078.695917
[1,0]<stdout>:TIME AFTER ITER #150 is 1586719079.406173
[1,0]<stdout>:Iter #150: 90.1 img/sec per GPU took 0.710103
[1,0]<stdout>:TIME BEFORE ITER #151 is 1586719079.406242
[1,0]<stdout>:TIME AFTER ITER #151 is 1586719080.122087
[1,0]<stdout>:Iter #151: 89.4 img/sec per GPU took 0.715692
[1,0]<stdout>:TIME BEFORE ITER #152 is 1586719080.122154
[1,0]<stdout>:TIME AFTER ITER #152 is 1586719080.829989
[1,0]<stdout>:Iter #152: 90.4 img/sec per GPU took 0.707648
[1,0]<stdout>:TIME BEFORE ITER #153 is 1586719080.830059
[1,0]<stdout>:TIME AFTER ITER #153 is 1586719081.542861
[1,0]<stdout>:Iter #153: 89.8 img/sec per GPU took 0.712649
[1,0]<stdout>:TIME BEFORE ITER #154 is 1586719081.542936
[1,0]<stdout>:TIME AFTER ITER #154 is 1586719082.252202
[1,0]<stdout>:Iter #154: 90.3 img/sec per GPU took 0.709085
[1,0]<stdout>:TIME BEFORE ITER #155 is 1586719082.252267
[1,0]<stdout>:TIME AFTER ITER #155 is 1586719082.960797
[1,0]<stdout>:Iter #155: 90.4 img/sec per GPU took 0.708342
[1,0]<stdout>:TIME BEFORE ITER #156 is 1586719082.960865
[1,0]<stdout>:TIME AFTER ITER #156 is 1586719083.669373
[1,0]<stdout>:Iter #156: 90.4 img/sec per GPU took 0.708307
[1,0]<stdout>:TIME BEFORE ITER #157 is 1586719083.669438
[1,0]<stdout>:TIME AFTER ITER #157 is 1586719084.378474
[1,0]<stdout>:Iter #157: 90.3 img/sec per GPU took 0.708850
[1,0]<stdout>:TIME BEFORE ITER #158 is 1586719084.378609
[1,0]<stdout>:TIME AFTER ITER #158 is 1586719085.089368
[1,0]<stdout>:Iter #158: 90.1 img/sec per GPU took 0.710556
[1,0]<stdout>:TIME BEFORE ITER #159 is 1586719085.089457
[1,0]<stdout>:TIME AFTER ITER #159 is 1586719085.801348
[1,0]<stdout>:Iter #159: 89.9 img/sec per GPU took 0.711726
[1,0]<stdout>:TIME BEFORE ITER #160 is 1586719085.801435
[1,0]<stdout>:TIME AFTER ITER #160 is 1586719086.510975
[1,0]<stdout>:Iter #160: 90.2 img/sec per GPU took 0.709372
[1,0]<stdout>:TIME BEFORE ITER #161 is 1586719086.511053
[1,0]<stdout>:TIME AFTER ITER #161 is 1586719087.221571
[1,0]<stdout>:Iter #161: 90.1 img/sec per GPU took 0.710335
[1,0]<stdout>:TIME BEFORE ITER #162 is 1586719087.221639
[1,0]<stdout>:TIME AFTER ITER #162 is 1586719087.929201
[1,0]<stdout>:Iter #162: 90.5 img/sec per GPU took 0.707404
[1,0]<stdout>:TIME BEFORE ITER #163 is 1586719087.929274
[1,0]<stdout>:TIME AFTER ITER #163 is 1586719088.640578
[1,0]<stdout>:Iter #163: 90.0 img/sec per GPU took 0.711139
[1,0]<stdout>:TIME BEFORE ITER #164 is 1586719088.640641
[1,0]<stdout>:TIME AFTER ITER #164 is 1586719089.349816
[1,0]<stdout>:Iter #164: 90.3 img/sec per GPU took 0.709029
[1,0]<stdout>:TIME BEFORE ITER #165 is 1586719089.349881
[1,0]<stdout>:TIME AFTER ITER #165 is 1586719090.057919
[1,0]<stdout>:Iter #165: 90.4 img/sec per GPU took 0.707869
[1,0]<stdout>:TIME BEFORE ITER #166 is 1586719090.057986
[1,0]<stdout>:TIME AFTER ITER #166 is 1586719090.768432
[1,0]<stdout>:Iter #166: 90.1 img/sec per GPU took 0.710282
[1,0]<stdout>:TIME BEFORE ITER #167 is 1586719090.768499
[1,0]<stdout>:TIME AFTER ITER #167 is 1586719091.477592
[1,0]<stdout>:Iter #167: 90.3 img/sec per GPU took 0.708914
[1,0]<stdout>:TIME BEFORE ITER #168 is 1586719091.477664
[1,0]<stdout>:TIME AFTER ITER #168 is 1586719092.185256
[1,0]<stdout>:Iter #168: 90.5 img/sec per GPU took 0.707440
[1,0]<stdout>:TIME BEFORE ITER #169 is 1586719092.185318
[1,0]<stdout>:TIME AFTER ITER #169 is 1586719092.893324
[1,0]<stdout>:Iter #169: 90.4 img/sec per GPU took 0.707852
[1,0]<stdout>:TIME BEFORE ITER #170 is 1586719092.893390
[1,0]<stdout>:TIME AFTER ITER #170 is 1586719093.603191
[1,0]<stdout>:Iter #170: 90.2 img/sec per GPU took 0.709630
[1,0]<stdout>:TIME BEFORE ITER #171 is 1586719093.603283
[1,0]<stdout>:TIME AFTER ITER #171 is 1586719094.310548
[1,0]<stdout>:Iter #171: 90.5 img/sec per GPU took 0.707082
[1,0]<stdout>:TIME BEFORE ITER #172 is 1586719094.310615
[1,0]<stdout>:TIME AFTER ITER #172 is 1586719095.015219
[1,0]<stdout>:Iter #172: 90.9 img/sec per GPU took 0.704452
[1,0]<stdout>:TIME BEFORE ITER #173 is 1586719095.015286
[1,0]<stdout>:TIME AFTER ITER #173 is 1586719095.726338
[1,0]<stdout>:Iter #173: 90.0 img/sec per GPU took 0.710903
[1,0]<stdout>:TIME BEFORE ITER #174 is 1586719095.726419
[1,0]<stdout>:TIME AFTER ITER #174 is 1586719096.431297
[1,0]<stdout>:Iter #174: 90.8 img/sec per GPU took 0.704651
[1,0]<stdout>:TIME BEFORE ITER #175 is 1586719096.431364
[1,0]<stdout>:TIME AFTER ITER #175 is 1586719097.143561
[1,0]<stdout>:Iter #175: 89.9 img/sec per GPU took 0.712016
[1,0]<stdout>:TIME BEFORE ITER #176 is 1586719097.143628
[1,0]<stdout>:TIME AFTER ITER #176 is 1586719097.857983
[1,0]<stdout>:Iter #176: 89.6 img/sec per GPU took 0.714190
[1,0]<stdout>:TIME BEFORE ITER #177 is 1586719097.858054
[1,0]<stdout>:TIME AFTER ITER #177 is 1586719098.563500
[1,0]<stdout>:Iter #177: 90.7 img/sec per GPU took 0.705278
[1,0]<stdout>:TIME BEFORE ITER #178 is 1586719098.563591
[1,0]<stdout>:TIME AFTER ITER #178 is 1586719099.275010
[1,0]<stdout>:Iter #178: 90.0 img/sec per GPU took 0.711206
[1,0]<stdout>:TIME BEFORE ITER #179 is 1586719099.275099
[1,0]<stdout>:TIME AFTER ITER #179 is 1586719099.978212
[1,0]<stdout>:Iter #179: 91.0 img/sec per GPU took 0.702916
[1,0]<stdout>:TIME BEFORE ITER #180 is 1586719099.978302
[1,0]<stdout>:TIME AFTER ITER #180 is 1586719100.683753
[1,0]<stdout>:Iter #180: 90.7 img/sec per GPU took 0.705268
[1,0]<stdout>:TIME BEFORE ITER #181 is 1586719100.683896
[1,0]<stdout>:TIME AFTER ITER #181 is 1586719101.387675
[1,0]<stdout>:Iter #181: 91.0 img/sec per GPU took 0.703592
[1,0]<stdout>:TIME BEFORE ITER #182 is 1586719101.387761
[1,0]<stdout>:TIME AFTER ITER #182 is 1586719102.090197
[1,0]<stdout>:Iter #182: 91.1 img/sec per GPU took 0.702260
[1,0]<stdout>:TIME BEFORE ITER #183 is 1586719102.090267
[1,0]<stdout>:TIME AFTER ITER #183 is 1586719102.801821
[1,0]<stdout>:Iter #183: 90.0 img/sec per GPU took 0.711418
[1,0]<stdout>:TIME BEFORE ITER #184 is 1586719102.801887
[1,0]<stdout>:TIME AFTER ITER #184 is 1586719103.507226
[1,0]<stdout>:Iter #184: 90.8 img/sec per GPU took 0.705187
[1,0]<stdout>:TIME BEFORE ITER #185 is 1586719103.507309
[1,0]<stdout>:TIME AFTER ITER #185 is 1586719104.208990
[1,0]<stdout>:Iter #185: 91.2 img/sec per GPU took 0.701505
[1,0]<stdout>:TIME BEFORE ITER #186 is 1586719104.209061
[1,0]<stdout>:TIME AFTER ITER #186 is 1586719104.913869
[1,0]<stdout>:Iter #186: 90.8 img/sec per GPU took 0.704651
[1,0]<stdout>:TIME BEFORE ITER #187 is 1586719104.913948
[1,0]<stdout>:TIME AFTER ITER #187 is 1586719105.618991
[1,0]<stdout>:Iter #187: 90.8 img/sec per GPU took 0.704876
[1,0]<stdout>:TIME BEFORE ITER #188 is 1586719105.619087
[1,0]<stdout>:TIME AFTER ITER #188 is 1586719106.325899
[1,0]<stdout>:Iter #188: 90.6 img/sec per GPU took 0.706643
[1,0]<stdout>:TIME BEFORE ITER #189 is 1586719106.325966
[1,0]<stdout>:TIME AFTER ITER #189 is 1586719107.021253
[1,0]<stdout>:Iter #189: 92.1 img/sec per GPU took 0.695088
[1,0]<stdout>:TIME BEFORE ITER #190 is 1586719107.021361
[1,0]<stdout>:TIME AFTER ITER #190 is 1586719107.725962
[1,0]<stdout>:Iter #190: 90.9 img/sec per GPU took 0.704418
[1,0]<stdout>:TIME BEFORE ITER #191 is 1586719107.726061
[1,0]<stdout>:TIME AFTER ITER #191 is 1586719108.424935
[1,0]<stdout>:Iter #191: 91.6 img/sec per GPU took 0.698679
[1,0]<stdout>:TIME BEFORE ITER #192 is 1586719108.425011
[1,0]<stdout>:TIME AFTER ITER #192 is 1586719109.125818
[1,0]<stdout>:Iter #192: 91.3 img/sec per GPU took 0.700634
[1,0]<stdout>:TIME BEFORE ITER #193 is 1586719109.125913
[1,0]<stdout>:TIME AFTER ITER #193 is 1586719109.827770
[1,0]<stdout>:Iter #193: 91.2 img/sec per GPU took 0.701686
[1,0]<stdout>:TIME BEFORE ITER #194 is 1586719109.827834
[1,0]<stdout>:TIME AFTER ITER #194 is 1586719110.533498
[1,0]<stdout>:Iter #194: 90.7 img/sec per GPU took 0.705504
[1,0]<stdout>:TIME BEFORE ITER #195 is 1586719110.533565
[1,0]<stdout>:TIME AFTER ITER #195 is 1586719111.234339
[1,0]<stdout>:Iter #195: 91.3 img/sec per GPU took 0.700630
[1,0]<stdout>:TIME BEFORE ITER #196 is 1586719111.234424
[1,0]<stdout>:TIME AFTER ITER #196 is 1586719111.933481
[1,0]<stdout>:Iter #196: 91.6 img/sec per GPU took 0.698826
[1,0]<stdout>:TIME BEFORE ITER #197 is 1586719111.933551
[1,0]<stdout>:TIME AFTER ITER #197 is 1586719112.637602
[1,0]<stdout>:Iter #197: 90.9 img/sec per GPU took 0.703891
[1,0]<stdout>:TIME BEFORE ITER #198 is 1586719112.637673
[1,0]<stdout>:TIME AFTER ITER #198 is 1586719113.338388
[1,0]<stdout>:Iter #198: 91.4 img/sec per GPU took 0.700555
[1,0]<stdout>:TIME BEFORE ITER #199 is 1586719113.338459
[1,0]<stdout>:TIME AFTER ITER #199 is 1586719114.034090
[1,0]<stdout>:Iter #199: 92.0 img/sec per GPU took 0.695460
[1,0]<stdout>:Img/sec per GPU: 90.2 +-4.0
[1,0]<stdout>:Total img/sec on 16 GPU(s): 1443.5 +-63.3
[hvd-t4-vm-1:07612] PMIX ERROR: BAD-PARAM in file src/dstore/pmix_esh.c at line 491
