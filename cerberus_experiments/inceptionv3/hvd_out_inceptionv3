[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,12]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,12]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,12]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,12]<stderr>:Instructions for updating:
[1,12]<stderr>:Colocations handled automatically by placer.
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,8]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,8]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,8]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,8]<stderr>:Instructions for updating:
[1,8]<stderr>:Colocations handled automatically by placer.
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,15]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,15]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,15]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,15]<stderr>:Instructions for updating:
[1,15]<stderr>:Colocations handled automatically by placer.
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,9]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,9]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,9]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,9]<stderr>:Instructions for updating:
[1,9]<stderr>:Colocations handled automatically by placer.
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,10]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,10]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,10]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,10]<stderr>:Instructions for updating:
[1,10]<stderr>:Colocations handled automatically by placer.
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,11]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,11]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,11]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,11]<stderr>:Instructions for updating:
[1,11]<stderr>:Colocations handled automatically by placer.
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,13]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,13]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,13]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,13]<stderr>:Instructions for updating:
[1,13]<stderr>:Colocations handled automatically by placer.
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,14]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,14]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,14]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,14]<stderr>:Instructions for updating:
[1,14]<stderr>:Colocations handled automatically by placer.
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,0]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,0]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,0]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,0]<stderr>:Instructions for updating:
[1,0]<stderr>:Colocations handled automatically by placer.
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,1]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,1]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,1]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,1]<stderr>:Instructions for updating:
[1,1]<stderr>:Colocations handled automatically by placer.
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,3]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,3]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,3]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,3]<stderr>:Instructions for updating:
[1,3]<stderr>:Colocations handled automatically by placer.
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,2]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,2]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,2]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,2]<stderr>:Instructions for updating:
[1,2]<stderr>:Colocations handled automatically by placer.
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,5]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,5]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,5]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,5]<stderr>:Instructions for updating:
[1,5]<stderr>:Colocations handled automatically by placer.
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,7]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,7]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,7]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,7]<stderr>:Instructions for updating:
[1,7]<stderr>:Colocations handled automatically by placer.
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,4]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,4]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,4]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,4]<stderr>:Instructions for updating:
[1,4]<stderr>:Colocations handled automatically by placer.
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
[1,6]<stderr>:/home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
[1,6]<stderr>:  np_resource = np.dtype([("resource", np.ubyte, 1)])
[1,6]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
[1,6]<stderr>:Instructions for updating:
[1,6]<stderr>:Colocations handled automatically by placer.
[1,7]<stderr>:2020-04-13 12:21:28.303049: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,3]<stderr>:2020-04-13 12:21:28.331631: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,4]<stderr>:2020-04-13 12:21:28.335015: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,0]<stdout>:Model: InceptionV3
[1,0]<stdout>:Batch size: 64
[1,0]<stdout>:Number of GPUs: 16
[1,0]<stderr>:2020-04-13 12:21:28.335543: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,1]<stderr>:2020-04-13 12:21:28.386521: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,6]<stderr>:2020-04-13 12:21:28.396496: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,5]<stderr>:2020-04-13 12:21:28.418098: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,2]<stderr>:2020-04-13 12:21:28.445906: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,12]<stderr>:2020-04-13 12:21:28.707757: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,3]<stderr>:2020-04-13 12:21:28.713515: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,2]<stderr>:2020-04-13 12:21:28.713553: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,0]<stderr>:2020-04-13 12:21:28.713594: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,1]<stderr>:2020-04-13 12:21:28.713662: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,10]<stderr>:2020-04-13 12:21:28.719149: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,9]<stderr>:2020-04-13 12:21:28.720495: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,3]<stderr>:2020-04-13 12:21:28.730596: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ef608e27b0 executing computations on platform Host. Devices:
[1,3]<stderr>:2020-04-13 12:21:28.730639: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,0]<stderr>:2020-04-13 12:21:28.730598: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x564ccdcfdae0 executing computations on platform Host. Devices:
[1,0]<stderr>:2020-04-13 12:21:28.730661: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,2]<stderr>:2020-04-13 12:21:28.730598: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562d618ae970 executing computations on platform Host. Devices:
[1,2]<stderr>:2020-04-13 12:21:28.730650: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,1]<stderr>:2020-04-13 12:21:28.730596: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x563895f05850 executing computations on platform Host. Devices:
[1,1]<stderr>:2020-04-13 12:21:28.730691: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,8]<stderr>:2020-04-13 12:21:28.731052: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,15]<stderr>:2020-04-13 12:21:28.734385: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,14]<stderr>:2020-04-13 12:21:28.735744: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,11]<stderr>:2020-04-13 12:21:28.738467: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,4]<stderr>:2020-04-13 12:21:28.749573: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,7]<stderr>:2020-04-13 12:21:28.749569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,6]<stderr>:2020-04-13 12:21:28.749568: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,5]<stderr>:2020-04-13 12:21:28.749569: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,6]<stderr>:2020-04-13 12:21:28.750922: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c39bc8a1a0 executing computations on platform Host. Devices:
[1,4]<stderr>:2020-04-13 12:21:28.750931: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x556b7568b1a0 executing computations on platform Host. Devices:
[1,4]<stderr>:2020-04-13 12:21:28.750954: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,7]<stderr>:2020-04-13 12:21:28.750921: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558ebb2e51a0 executing computations on platform Host. Devices:
[1,7]<stderr>:2020-04-13 12:21:28.750955: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,5]<stderr>:2020-04-13 12:21:28.750920: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c09532a700 executing computations on platform Host. Devices:
[1,5]<stderr>:2020-04-13 12:21:28.750955: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,6]<stderr>:2020-04-13 12:21:28.750982: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,13]<stderr>:2020-04-13 12:21:28.762088: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
[1,10]<stderr>:2020-04-13 12:21:28.956657: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,8]<stderr>:2020-04-13 12:21:28.956647: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,11]<stderr>:2020-04-13 12:21:28.956700: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,9]<stderr>:2020-04-13 12:21:28.956700: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,11]<stderr>:2020-04-13 12:21:28.958278: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5567500661a0 executing computations on platform Host. Devices:
[1,11]<stderr>:2020-04-13 12:21:28.958308: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,8]<stderr>:2020-04-13 12:21:28.958269: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55799409e1a0 executing computations on platform Host. Devices:
[1,8]<stderr>:2020-04-13 12:21:28.958303: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,10]<stderr>:2020-04-13 12:21:28.958260: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562c425ebd20 executing computations on platform Host. Devices:
[1,9]<stderr>:2020-04-13 12:21:28.958275: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55925188c1a0 executing computations on platform Host. Devices:
[1,9]<stderr>:2020-04-13 12:21:28.958301: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,10]<stderr>:2020-04-13 12:21:28.958340: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,12]<stderr>:2020-04-13 12:21:29.047346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,14]<stderr>:2020-04-13 12:21:29.047399: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,15]<stderr>:2020-04-13 12:21:29.047352: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,13]<stderr>:2020-04-13 12:21:29.047375: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz
[1,13]<stderr>:2020-04-13 12:21:29.048889: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557c98fee1a0 executing computations on platform Host. Devices:
[1,15]<stderr>:2020-04-13 12:21:29.048911: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56208f20d1a0 executing computations on platform Host. Devices:
[1,15]<stderr>:2020-04-13 12:21:29.048938: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,12]<stderr>:2020-04-13 12:21:29.048898: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x56360f0d91a0 executing computations on platform Host. Devices:
[1,12]<stderr>:2020-04-13 12:21:29.048939: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,14]<stderr>:2020-04-13 12:21:29.048908: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5604dac121a0 executing computations on platform Host. Devices:
[1,14]<stderr>:2020-04-13 12:21:29.048939: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,13]<stderr>:2020-04-13 12:21:29.048980: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
[1,3]<stderr>:2020-04-13 12:21:30.209398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-13 12:21:30.209416: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-04-13 12:21:30.209401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-04-13 12:21:30.209502: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-13 12:21:30.214105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,3]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,3]<stderr>:pciBusID: 0000:00:07.0
[1,3]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,3]<stderr>:2020-04-13 12:21:30.214132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,1]<stderr>:2020-04-13 12:21:30.214244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,1]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,1]<stderr>:pciBusID: 0000:00:05.0
[1,1]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,1]<stderr>:2020-04-13 12:21:30.214274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,0]<stderr>:2020-04-13 12:21:30.214330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,0]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,0]<stderr>:pciBusID: 0000:00:04.0
[1,0]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,0]<stderr>:2020-04-13 12:21:30.214359: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,2]<stderr>:2020-04-13 12:21:30.214402: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,2]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,2]<stderr>:pciBusID: 0000:00:06.0
[1,2]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,2]<stderr>:2020-04-13 12:21:30.214431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,5]<stderr>:2020-04-13 12:21:30.230160: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-13 12:21:30.230154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-04-13 12:21:30.230202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-13 12:21:30.230202: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-13 12:21:30.234278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,6]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,6]<stderr>:pciBusID: 0000:00:06.0
[1,6]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,6]<stderr>:2020-04-13 12:21:30.234306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,5]<stderr>:2020-04-13 12:21:30.234332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,5]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,5]<stderr>:pciBusID: 0000:00:05.0
[1,5]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,5]<stderr>:2020-04-13 12:21:30.234392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,4]<stderr>:2020-04-13 12:21:30.234398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,4]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,4]<stderr>:pciBusID: 0000:00:04.0
[1,4]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,4]<stderr>:2020-04-13 12:21:30.234424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,7]<stderr>:2020-04-13 12:21:30.234452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,7]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,7]<stderr>:pciBusID: 0000:00:07.0
[1,7]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,7]<stderr>:2020-04-13 12:21:30.234491: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,1]<stderr>:2020-04-13 12:21:30.266459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,1]<stderr>:2020-04-13 12:21:30.266481: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,1]<stderr>:2020-04-13 12:21:30.266487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,2]<stderr>:2020-04-13 12:21:30.266433: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,2]<stderr>:2020-04-13 12:21:30.266474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,2]<stderr>:2020-04-13 12:21:30.266484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,3]<stderr>:2020-04-13 12:21:30.266511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,3]<stderr>:2020-04-13 12:21:30.266530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,3]<stderr>:2020-04-13 12:21:30.266535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,0]<stderr>:2020-04-13 12:21:30.266581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,0]<stderr>:2020-04-13 12:21:30.266602: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,0]<stderr>:2020-04-13 12:21:30.266610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,1]<stderr>:2020-04-13 12:21:30.266654: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,2]<stderr>:2020-04-13 12:21:30.266682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,3]<stderr>:2020-04-13 12:21:30.266676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,0]<stderr>:2020-04-13 12:21:30.266712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,6]<stderr>:2020-04-13 12:21:30.280035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,6]<stderr>:2020-04-13 12:21:30.280061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,6]<stderr>:2020-04-13 12:21:30.280067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,4]<stderr>:2020-04-13 12:21:30.280106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,4]<stderr>:2020-04-13 12:21:30.280128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,4]<stderr>:2020-04-13 12:21:30.280136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,7]<stderr>:2020-04-13 12:21:30.280165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,7]<stderr>:2020-04-13 12:21:30.280190: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,7]<stderr>:2020-04-13 12:21:30.280198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,5]<stderr>:2020-04-13 12:21:30.280211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,5]<stderr>:2020-04-13 12:21:30.280230: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,5]<stderr>:2020-04-13 12:21:30.280236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,6]<stderr>:2020-04-13 12:21:30.280307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,4]<stderr>:2020-04-13 12:21:30.280320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,7]<stderr>:2020-04-13 12:21:30.280337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,5]<stderr>:2020-04-13 12:21:30.280354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,11]<stderr>:2020-04-13 12:21:30.421813: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-13 12:21:30.421812: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-13 12:21:30.421843: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-13 12:21:30.421868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-13 12:21:30.426210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,8]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,8]<stderr>:pciBusID: 0000:00:04.0
[1,8]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,8]<stderr>:2020-04-13 12:21:30.426236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,11]<stderr>:2020-04-13 12:21:30.426261: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,11]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,11]<stderr>:pciBusID: 0000:00:07.0
[1,11]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,11]<stderr>:2020-04-13 12:21:30.426282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,10]<stderr>:2020-04-13 12:21:30.426342: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,10]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,10]<stderr>:pciBusID: 0000:00:06.0
[1,10]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,10]<stderr>:2020-04-13 12:21:30.426394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,9]<stderr>:2020-04-13 12:21:30.426401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,9]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,9]<stderr>:pciBusID: 0000:00:05.0
[1,9]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,9]<stderr>:2020-04-13 12:21:30.426425: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,8]<stderr>:2020-04-13 12:21:30.467703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,8]<stderr>:2020-04-13 12:21:30.467731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,8]<stderr>:2020-04-13 12:21:30.467738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,11]<stderr>:2020-04-13 12:21:30.467755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,11]<stderr>:2020-04-13 12:21:30.467776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,11]<stderr>:2020-04-13 12:21:30.467782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,9]<stderr>:2020-04-13 12:21:30.467827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,9]<stderr>:2020-04-13 12:21:30.467866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,9]<stderr>:2020-04-13 12:21:30.467873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,10]<stderr>:2020-04-13 12:21:30.467880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,10]<stderr>:2020-04-13 12:21:30.467901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,10]<stderr>:2020-04-13 12:21:30.467908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,8]<stderr>:2020-04-13 12:21:30.467959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,9]<stderr>:2020-04-13 12:21:30.467976: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,11]<stderr>:2020-04-13 12:21:30.467958: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,10]<stderr>:2020-04-13 12:21:30.468005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,14]<stderr>:2020-04-13 12:21:30.602538: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-13 12:21:30.602563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-13 12:21:30.602604: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-13 12:21:30.602540: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,14]<stderr>:2020-04-13 12:21:30.607290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,14]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,14]<stderr>:pciBusID: 0000:00:06.0
[1,14]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,14]<stderr>:2020-04-13 12:21:30.607326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 2
[1,13]<stderr>:2020-04-13 12:21:30.607350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,13]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,13]<stderr>:pciBusID: 0000:00:05.0
[1,13]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,13]<stderr>:2020-04-13 12:21:30.607378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 1
[1,15]<stderr>:2020-04-13 12:21:30.607400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,15]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,15]<stderr>:pciBusID: 0000:00:07.0
[1,15]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,15]<stderr>:2020-04-13 12:21:30.607428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 3
[1,12]<stderr>:2020-04-13 12:21:30.607457: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: 
[1,12]<stderr>:name: Tesla T4 major: 7 minor: 5 memoryClockRate(GHz): 1.59
[1,12]<stderr>:pciBusID: 0000:00:04.0
[1,12]<stderr>:totalMemory: 14.75GiB freeMemory: 14.65GiB
[1,12]<stderr>:2020-04-13 12:21:30.607485: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0
[1,15]<stderr>:2020-04-13 12:21:30.653648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,15]<stderr>:2020-04-13 12:21:30.653674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      3 
[1,15]<stderr>:2020-04-13 12:21:30.653681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 3:   N 
[1,12]<stderr>:2020-04-13 12:21:30.653709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,12]<stderr>:2020-04-13 12:21:30.653731: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 
[1,12]<stderr>:2020-04-13 12:21:30.653741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N 
[1,13]<stderr>:2020-04-13 12:21:30.653763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,13]<stderr>:2020-04-13 12:21:30.653784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      1 
[1,13]<stderr>:2020-04-13 12:21:30.653790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   N 
[1,14]<stderr>:2020-04-13 12:21:30.653833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:
[1,14]<stderr>:2020-04-13 12:21:30.653853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      2 
[1,14]<stderr>:2020-04-13 12:21:30.653860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 2:   N 
[1,15]<stderr>:2020-04-13 12:21:30.653901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 3, name: Tesla T4, pci bus id: 0000:00:07.0, compute capability: 7.5)
[1,13]<stderr>:2020-04-13 12:21:30.653912: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5)
[1,12]<stderr>:2020-04-13 12:21:30.653901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)
[1,14]<stderr>:2020-04-13 12:21:30.653935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14249 MB memory) -> physical GPU (device: 2, name: Tesla T4, pci bus id: 0000:00:06.0, compute capability: 7.5)
[1,5]<stderr>:2020-04-13 12:21:32.424562: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-04-13 12:21:32.455643: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-13 12:21:32.487814: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-13 12:21:32.498103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-04-13 12:21:32.504708: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-04-13 12:21:32.517691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,5]<stderr>:2020-04-13 12:21:32.522552: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c0983df980 executing computations on platform CUDA. Devices:
[1,5]<stderr>:2020-04-13 12:21:32.522581: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,5]<stderr>:2020-04-13 12:21:32.522587: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,5]<stderr>:2020-04-13 12:21:32.522592: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,5]<stderr>:2020-04-13 12:21:32.522596: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-13 12:21:32.523270: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-13 12:21:32.526578: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-13 12:21:32.526936: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-04-13 12:21:32.529410: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-13 12:21:32.550967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,4]<stderr>:2020-04-13 12:21:32.559249: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-13 12:21:32.559229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,7]<stderr>:2020-04-13 12:21:32.560741: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,6]<stderr>:2020-04-13 12:21:32.562753: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55c39fe02190 executing computations on platform CUDA. Devices:
[1,6]<stderr>:2020-04-13 12:21:32.562784: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:2020-04-13 12:21:32.562790: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:2020-04-13 12:21:32.562795: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:2020-04-13 12:21:32.562799: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:2020-04-13 12:21:32.562789: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x556b79802ac0 executing computations on platform CUDA. Devices:
[1,4]<stderr>:2020-04-13 12:21:32.562808: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:2020-04-13 12:21:32.562814: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:2020-04-13 12:21:32.562818: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,4]<stderr>:2020-04-13 12:21:32.562823: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-13 12:21:32.563796: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x558ebf45c700 executing computations on platform CUDA. Devices:
[1,7]<stderr>:2020-04-13 12:21:32.563824: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-13 12:21:32.563830: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-13 12:21:32.563835: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,7]<stderr>:2020-04-13 12:21:32.563839: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-13 12:21:32.605288: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-13 12:21:32.615831: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-04-13 12:21:32.618314: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-13 12:21:32.619691: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,0]<stderr>:2020-04-13 12:21:32.626313: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x564cce37ec00 executing computations on platform CUDA. Devices:
[1,0]<stderr>:2020-04-13 12:21:32.626349: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-13 12:21:32.626360: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-13 12:21:32.626367: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,0]<stderr>:2020-04-13 12:21:32.626375: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-13 12:21:32.634922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-13 12:21:32.639834: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,2]<stderr>:2020-04-13 12:21:32.641790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-04-13 12:21:32.665057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-13 12:21:32.668628: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,1]<stderr>:2020-04-13 12:21:32.669018: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x563896586d90 executing computations on platform CUDA. Devices:
[1,1]<stderr>:2020-04-13 12:21:32.669046: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-13 12:21:32.669052: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-13 12:21:32.669057: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,1]<stderr>:2020-04-13 12:21:32.669062: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-13 12:21:32.669897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,3]<stderr>:2020-04-13 12:21:32.671189: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55ef60f63b00 executing computations on platform CUDA. Devices:
[1,3]<stderr>:2020-04-13 12:21:32.671225: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,3]<stderr>:2020-04-13 12:21:32.671234: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,3]<stderr>:2020-04-13 12:21:32.671242: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,3]<stderr>:2020-04-13 12:21:32.671250: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-13 12:21:32.672158: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562d6435b500 executing computations on platform CUDA. Devices:
[1,2]<stderr>:2020-04-13 12:21:32.672183: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-13 12:21:32.672189: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-13 12:21:32.672194: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,2]<stderr>:2020-04-13 12:21:32.672198: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-13 12:21:32.856880: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-13 12:21:32.893302: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-13 12:21:32.923400: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-13 12:21:32.951457: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-13 12:21:32.953354: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-13 12:21:32.964660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-13 12:21:32.965401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,8]<stderr>:2020-04-13 12:21:32.970136: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557998216540 executing computations on platform CUDA. Devices:
[1,8]<stderr>:2020-04-13 12:21:32.970165: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-13 12:21:32.970171: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-13 12:21:32.970176: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,8]<stderr>:2020-04-13 12:21:32.970180: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-13 12:21:32.977163: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-13 12:21:32.979125: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-13 12:21:32.980784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-13 12:21:32.998531: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,11]<stderr>:2020-04-13 12:21:33.002000: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5567541de130 executing computations on platform CUDA. Devices:
[1,11]<stderr>:2020-04-13 12:21:33.002031: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,11]<stderr>:2020-04-13 12:21:33.002037: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,11]<stderr>:2020-04-13 12:21:33.002042: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,11]<stderr>:2020-04-13 12:21:33.002048: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-13 12:21:33.006345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,9]<stderr>:2020-04-13 12:21:33.007069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-13 12:21:33.007967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,10]<stderr>:2020-04-13 12:21:33.008679: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562c42c6b340 executing computations on platform CUDA. Devices:
[1,10]<stderr>:2020-04-13 12:21:33.008712: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-13 12:21:33.008719: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-13 12:21:33.008724: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,10]<stderr>:2020-04-13 12:21:33.008729: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-13 12:21:33.009973: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x559255a03590 executing computations on platform CUDA. Devices:
[1,9]<stderr>:2020-04-13 12:21:33.010006: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-13 12:21:33.010014: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-13 12:21:33.010019: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,9]<stderr>:2020-04-13 12:21:33.010025: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,13]<stderr>:2020-04-13 12:21:33.032757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,14]<stderr>:2020-04-13 12:21:33.046349: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-13 12:21:33.062757: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-13 12:21:33.076847: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-13 12:21:33.081251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,15]<stderr>:2020-04-13 12:21:33.081675: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x562093384b70 executing computations on platform CUDA. Devices:
[1,15]<stderr>:2020-04-13 12:21:33.081717: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-13 12:21:33.081728: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-13 12:21:33.081736: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,15]<stderr>:2020-04-13 12:21:33.081744: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-13 12:21:33.088383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-13 12:21:33.088717: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-13 12:21:33.113236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,13]<stderr>:2020-04-13 12:21:33.117431: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x557c9d165210 executing computations on platform CUDA. Devices:
[1,13]<stderr>:2020-04-13 12:21:33.117461: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,13]<stderr>:2020-04-13 12:21:33.117468: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,13]<stderr>:2020-04-13 12:21:33.117473: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,13]<stderr>:2020-04-13 12:21:33.117478: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-13 12:21:33.119228: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,12]<stderr>:2020-04-13 12:21:33.119475: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
[1,14]<stderr>:2020-04-13 12:21:33.121755: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5604ded88c90 executing computations on platform CUDA. Devices:
[1,14]<stderr>:2020-04-13 12:21:33.121792: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-13 12:21:33.121802: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-13 12:21:33.121810: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,14]<stderr>:2020-04-13 12:21:33.121818: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-13 12:21:33.121884: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x563613250bd0 executing computations on platform CUDA. Devices:
[1,12]<stderr>:2020-04-13 12:21:33.121921: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-13 12:21:33.121935: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-13 12:21:33.121943: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (2): Tesla T4, Compute Capability 7.5
[1,12]<stderr>:2020-04-13 12:21:33.121950: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (3): Tesla T4, Compute Capability 7.5
[1,6]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,6]<stderr>:Instructions for updating:
[1,6]<stderr>:Use tf.cast instead.
[1,1]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,1]<stderr>:Instructions for updating:
[1,1]<stderr>:Use tf.cast instead.
[1,3]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,3]<stderr>:Instructions for updating:
[1,3]<stderr>:Use tf.cast instead.
[1,2]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,2]<stderr>:Instructions for updating:
[1,2]<stderr>:Use tf.cast instead.
[1,5]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,5]<stderr>:Instructions for updating:
[1,5]<stderr>:Use tf.cast instead.
[1,0]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,0]<stderr>:Instructions for updating:
[1,0]<stderr>:Use tf.cast instead.
[1,4]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,4]<stderr>:Instructions for updating:
[1,4]<stderr>:Use tf.cast instead.
[1,7]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,7]<stderr>:Instructions for updating:
[1,7]<stderr>:Use tf.cast instead.
[1,8]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,8]<stderr>:Instructions for updating:
[1,8]<stderr>:Use tf.cast instead.
[1,6]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,6]<stderr>:Instructions for updating:
[1,6]<stderr>:Use tf.cast instead.
[1,1]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,1]<stderr>:Instructions for updating:
[1,1]<stderr>:Use tf.cast instead.
[1,3]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,3]<stderr>:Instructions for updating:
[1,3]<stderr>:Use tf.cast instead.
[1,10]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,10]<stderr>:Instructions for updating:
[1,10]<stderr>:Use tf.cast instead.
[1,2]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,2]<stderr>:Instructions for updating:
[1,2]<stderr>:Use tf.cast instead.
[1,5]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,5]<stderr>:Instructions for updating:
[1,5]<stderr>:Use tf.cast instead.
[1,12]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,12]<stderr>:Instructions for updating:
[1,12]<stderr>:Use tf.cast instead.
[1,0]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,0]<stderr>:Instructions for updating:
[1,0]<stderr>:Use tf.cast instead.
[1,13]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,13]<stderr>:Instructions for updating:
[1,13]<stderr>:Use tf.cast instead.
[1,14]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,14]<stderr>:Instructions for updating:
[1,14]<stderr>:Use tf.cast instead.
[1,4]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,4]<stderr>:Instructions for updating:
[1,4]<stderr>:Use tf.cast instead.
[1,15]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,15]<stderr>:Instructions for updating:
[1,15]<stderr>:Use tf.cast instead.
[1,7]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,7]<stderr>:Instructions for updating:
[1,7]<stderr>:Use tf.cast instead.
[1,11]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,11]<stderr>:Instructions for updating:
[1,11]<stderr>:Use tf.cast instead.
[1,8]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,8]<stderr>:Instructions for updating:
[1,8]<stderr>:Use tf.cast instead.
[1,9]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,9]<stderr>:Instructions for updating:
[1,9]<stderr>:Use tf.cast instead.
[1,10]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,10]<stderr>:Instructions for updating:
[1,10]<stderr>:Use tf.cast instead.
[1,12]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,12]<stderr>:Instructions for updating:
[1,12]<stderr>:Use tf.cast instead.
[1,13]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,13]<stderr>:Instructions for updating:
[1,13]<stderr>:Use tf.cast instead.
[1,14]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,14]<stderr>:Instructions for updating:
[1,14]<stderr>:Use tf.cast instead.
[1,15]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,15]<stderr>:Instructions for updating:
[1,15]<stderr>:Use tf.cast instead.
[1,11]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,11]<stderr>:Instructions for updating:
[1,11]<stderr>:Use tf.cast instead.
[1,9]<stderr>:WARNING:tensorflow:From /home/gcp_ghobadi_google_mit_edu/gpu-tf/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
[1,9]<stderr>:Instructions for updating:
[1,9]<stderr>:Use tf.cast instead.
[1,0]<stdout>:Running warmup...
[1,6]<stderr>:2020-04-13 12:21:45.812777: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,5]<stderr>:2020-04-13 12:21:45.812740: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,4]<stderr>:2020-04-13 12:21:45.812745: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,7]<stderr>:2020-04-13 12:21:45.812738: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,2]<stderr>:2020-04-13 12:21:45.834018: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,3]<stderr>:2020-04-13 12:21:46.192618: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,11]<stderr>:2020-04-13 12:21:46.222344: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,10]<stderr>:2020-04-13 12:21:46.222391: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,9]<stderr>:2020-04-13 12:21:46.222341: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,8]<stderr>:2020-04-13 12:21:46.222431: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,1]<stderr>:2020-04-13 12:21:46.272988: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,0]<stderr>:2020-04-13 12:21:46.291860: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,13]<stderr>:2020-04-13 12:21:46.306939: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,12]<stderr>:2020-04-13 12:21:46.306975: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,14]<stderr>:2020-04-13 12:21:46.306934: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,15]<stderr>:2020-04-13 12:21:46.306936: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally
[1,0]<stdout>:Running benchmark...
[1,0]<stdout>:TIME BEFORE ITER #0 is 1586780518.570429
[1,0]<stdout>:TIME AFTER ITER #0 is 1586780519.053127
[1,0]<stdout>:Iter #0: 132.6 img/sec per GPU took 0.482490
[1,0]<stdout>:TIME BEFORE ITER #1 is 1586780519.053190
[1,0]<stdout>:TIME AFTER ITER #1 is 1586780519.545052
[1,0]<stdout>:Iter #1: 130.2 img/sec per GPU took 0.491686
[1,0]<stdout>:TIME BEFORE ITER #2 is 1586780519.545119
[1,0]<stdout>:TIME AFTER ITER #2 is 1586780520.030054
[1,0]<stdout>:Iter #2: 132.0 img/sec per GPU took 0.484745
[1,0]<stdout>:TIME BEFORE ITER #3 is 1586780520.030133
[1,0]<stdout>:TIME AFTER ITER #3 is 1586780520.518077
[1,0]<stdout>:Iter #3: 131.2 img/sec per GPU took 0.487738
[1,0]<stdout>:TIME BEFORE ITER #4 is 1586780520.518171
[1,0]<stdout>:TIME AFTER ITER #4 is 1586780521.009988
[1,0]<stdout>:Iter #4: 130.2 img/sec per GPU took 0.491590
[1,0]<stdout>:TIME BEFORE ITER #5 is 1586780521.010061
[1,0]<stdout>:TIME AFTER ITER #5 is 1586780521.503636
[1,0]<stdout>:Iter #5: 129.7 img/sec per GPU took 0.493391
[1,0]<stdout>:TIME BEFORE ITER #6 is 1586780521.503717
[1,0]<stdout>:TIME AFTER ITER #6 is 1586780522.000460
[1,0]<stdout>:Iter #6: 128.9 img/sec per GPU took 0.496545
[1,0]<stdout>:TIME BEFORE ITER #7 is 1586780522.000538
[1,0]<stdout>:TIME AFTER ITER #7 is 1586780522.481337
[1,0]<stdout>:Iter #7: 133.2 img/sec per GPU took 0.480621
[1,0]<stdout>:TIME BEFORE ITER #8 is 1586780522.481417
[1,0]<stdout>:TIME AFTER ITER #8 is 1586780522.995942
[1,0]<stdout>:Iter #8: 124.4 img/sec per GPU took 0.514332
[1,0]<stdout>:TIME BEFORE ITER #9 is 1586780522.996020
[1,0]<stdout>:TIME AFTER ITER #9 is 1586780523.478075
[1,0]<stdout>:Iter #9: 132.8 img/sec per GPU took 0.481866
[1,0]<stdout>:TIME BEFORE ITER #10 is 1586780523.478158
[1,0]<stdout>:TIME AFTER ITER #10 is 1586780523.979717
[1,0]<stdout>:Iter #10: 127.7 img/sec per GPU took 0.501307
[1,0]<stdout>:TIME BEFORE ITER #11 is 1586780523.979803
[1,0]<stdout>:TIME AFTER ITER #11 is 1586780524.484715
[1,0]<stdout>:Iter #11: 126.8 img/sec per GPU took 0.504716
[1,0]<stdout>:TIME BEFORE ITER #12 is 1586780524.484779
[1,0]<stdout>:TIME AFTER ITER #12 is 1586780524.983749
[1,0]<stdout>:Iter #12: 128.3 img/sec per GPU took 0.498798
[1,0]<stdout>:TIME BEFORE ITER #13 is 1586780524.983815
[1,0]<stdout>:TIME AFTER ITER #13 is 1586780525.484448
[1,0]<stdout>:Iter #13: 127.9 img/sec per GPU took 0.500480
[1,0]<stdout>:TIME BEFORE ITER #14 is 1586780525.484508
[1,0]<stdout>:TIME AFTER ITER #14 is 1586780525.985323
[1,0]<stdout>:Iter #14: 127.8 img/sec per GPU took 0.500644
[1,0]<stdout>:TIME BEFORE ITER #15 is 1586780525.985384
[1,0]<stdout>:TIME AFTER ITER #15 is 1586780526.487197
[1,0]<stdout>:Iter #15: 127.6 img/sec per GPU took 0.501667
[1,0]<stdout>:TIME BEFORE ITER #16 is 1586780526.487420
[1,0]<stdout>:TIME AFTER ITER #16 is 1586780526.982920
[1,0]<stdout>:Iter #16: 129.2 img/sec per GPU took 0.495346
[1,0]<stdout>:TIME BEFORE ITER #17 is 1586780526.982986
[1,0]<stdout>:TIME AFTER ITER #17 is 1586780527.476129
[1,0]<stdout>:Iter #17: 129.8 img/sec per GPU took 0.492983
[1,0]<stdout>:TIME BEFORE ITER #18 is 1586780527.476207
[1,0]<stdout>:TIME AFTER ITER #18 is 1586780528.000843
[1,0]<stdout>:Iter #18: 122.0 img/sec per GPU took 0.524430
[1,0]<stdout>:TIME BEFORE ITER #19 is 1586780528.000926
[1,0]<stdout>:TIME AFTER ITER #19 is 1586780528.505269
[1,0]<stdout>:Iter #19: 127.0 img/sec per GPU took 0.504122
[1,0]<stdout>:TIME BEFORE ITER #20 is 1586780528.505351
[1,0]<stdout>:TIME AFTER ITER #20 is 1586780529.003405
[1,0]<stdout>:Iter #20: 128.6 img/sec per GPU took 0.497844
[1,0]<stdout>:TIME BEFORE ITER #21 is 1586780529.003465
[1,0]<stdout>:TIME AFTER ITER #21 is 1586780529.504920
[1,0]<stdout>:Iter #21: 127.7 img/sec per GPU took 0.501301
[1,0]<stdout>:TIME BEFORE ITER #22 is 1586780529.505007
[1,0]<stdout>:TIME AFTER ITER #22 is 1586780529.993010
[1,0]<stdout>:Iter #22: 131.2 img/sec per GPU took 0.487818
[1,0]<stdout>:TIME BEFORE ITER #23 is 1586780529.993106
[1,0]<stdout>:TIME AFTER ITER #23 is 1586780530.492241
[1,0]<stdout>:Iter #23: 128.3 img/sec per GPU took 0.498948
[1,0]<stdout>:TIME BEFORE ITER #24 is 1586780530.492332
[1,0]<stdout>:TIME AFTER ITER #24 is 1586780530.990174
[1,0]<stdout>:Iter #24: 128.6 img/sec per GPU took 0.497627
[1,0]<stdout>:TIME BEFORE ITER #25 is 1586780530.990267
[1,0]<stdout>:TIME AFTER ITER #25 is 1586780531.484694
[1,0]<stdout>:Iter #25: 129.5 img/sec per GPU took 0.494174
[1,0]<stdout>:TIME BEFORE ITER #26 is 1586780531.484799
[1,0]<stdout>:TIME AFTER ITER #26 is 1586780531.988822
[1,0]<stdout>:Iter #26: 127.0 img/sec per GPU took 0.503788
[1,0]<stdout>:TIME BEFORE ITER #27 is 1586780531.988928
[1,0]<stdout>:TIME AFTER ITER #27 is 1586780532.496412
[1,0]<stdout>:Iter #27: 126.2 img/sec per GPU took 0.507208
[1,0]<stdout>:TIME BEFORE ITER #28 is 1586780532.496497
[1,0]<stdout>:TIME AFTER ITER #28 is 1586780533.005781
[1,0]<stdout>:Iter #28: 125.7 img/sec per GPU took 0.509044
[1,0]<stdout>:TIME BEFORE ITER #29 is 1586780533.005886
[1,0]<stdout>:TIME AFTER ITER #29 is 1586780533.517831
[1,0]<stdout>:Iter #29: 125.1 img/sec per GPU took 0.511682
[1,0]<stdout>:TIME BEFORE ITER #30 is 1586780533.517926
[1,0]<stdout>:TIME AFTER ITER #30 is 1586780534.014767
[1,0]<stdout>:Iter #30: 128.9 img/sec per GPU took 0.496626
[1,0]<stdout>:TIME BEFORE ITER #31 is 1586780534.014845
[1,0]<stdout>:TIME AFTER ITER #31 is 1586780534.518832
[1,0]<stdout>:Iter #31: 127.0 img/sec per GPU took 0.503761
[1,0]<stdout>:TIME BEFORE ITER #32 is 1586780534.518905
[1,0]<stdout>:TIME AFTER ITER #32 is 1586780535.024913
[1,0]<stdout>:Iter #32: 126.5 img/sec per GPU took 0.505840
[1,0]<stdout>:TIME BEFORE ITER #33 is 1586780535.024994
[1,0]<stdout>:TIME AFTER ITER #33 is 1586780535.537381
[1,0]<stdout>:Iter #33: 125.0 img/sec per GPU took 0.512190
[1,0]<stdout>:TIME BEFORE ITER #34 is 1586780535.537472
[1,0]<stdout>:TIME AFTER ITER #34 is 1586780536.037888
[1,0]<stdout>:Iter #34: 128.0 img/sec per GPU took 0.500165
[1,0]<stdout>:TIME BEFORE ITER #35 is 1586780536.037954
[1,0]<stdout>:TIME AFTER ITER #35 is 1586780536.547144
[1,0]<stdout>:Iter #35: 125.7 img/sec per GPU took 0.509050
[1,0]<stdout>:TIME BEFORE ITER #36 is 1586780536.547210
[1,0]<stdout>:TIME AFTER ITER #36 is 1586780537.052688
[1,0]<stdout>:Iter #36: 126.6 img/sec per GPU took 0.505332
[1,0]<stdout>:TIME BEFORE ITER #37 is 1586780537.052753
[1,0]<stdout>:TIME AFTER ITER #37 is 1586780537.568996
[1,0]<stdout>:Iter #37: 124.0 img/sec per GPU took 0.516028
[1,0]<stdout>:TIME BEFORE ITER #38 is 1586780537.569089
[1,0]<stdout>:TIME AFTER ITER #38 is 1586780538.087025
[1,0]<stdout>:Iter #38: 123.6 img/sec per GPU took 0.517758
[1,0]<stdout>:TIME BEFORE ITER #39 is 1586780538.087097
[1,0]<stdout>:TIME AFTER ITER #39 is 1586780538.597854
[1,0]<stdout>:Iter #39: 125.3 img/sec per GPU took 0.510575
[1,0]<stdout>:TIME BEFORE ITER #40 is 1586780538.597944
[1,0]<stdout>:TIME AFTER ITER #40 is 1586780539.109989
[1,0]<stdout>:Iter #40: 125.0 img/sec per GPU took 0.511848
[1,0]<stdout>:TIME BEFORE ITER #41 is 1586780539.110065
[1,0]<stdout>:TIME AFTER ITER #41 is 1586780539.631342
[1,0]<stdout>:Iter #41: 122.8 img/sec per GPU took 0.521121
[1,0]<stdout>:TIME BEFORE ITER #42 is 1586780539.631437
[1,0]<stdout>:TIME AFTER ITER #42 is 1586780540.149340
[1,0]<stdout>:Iter #42: 123.6 img/sec per GPU took 0.517717
[1,0]<stdout>:TIME BEFORE ITER #43 is 1586780540.149417
[1,0]<stdout>:TIME AFTER ITER #43 is 1586780540.661925
[1,0]<stdout>:Iter #43: 124.9 img/sec per GPU took 0.512297
[1,0]<stdout>:TIME BEFORE ITER #44 is 1586780540.662007
[1,0]<stdout>:TIME AFTER ITER #44 is 1586780541.183363
[1,0]<stdout>:Iter #44: 122.8 img/sec per GPU took 0.521175
[1,0]<stdout>:TIME BEFORE ITER #45 is 1586780541.183443
[1,0]<stdout>:TIME AFTER ITER #45 is 1586780541.703413
[1,0]<stdout>:Iter #45: 123.1 img/sec per GPU took 0.519781
[1,0]<stdout>:TIME BEFORE ITER #46 is 1586780541.703494
[1,0]<stdout>:TIME AFTER ITER #46 is 1586780542.224080
[1,0]<stdout>:Iter #46: 123.0 img/sec per GPU took 0.520347
[1,0]<stdout>:TIME BEFORE ITER #47 is 1586780542.224151
[1,0]<stdout>:TIME AFTER ITER #47 is 1586780542.742234
[1,0]<stdout>:Iter #47: 123.6 img/sec per GPU took 0.517871
[1,0]<stdout>:TIME BEFORE ITER #48 is 1586780542.742339
[1,0]<stdout>:TIME AFTER ITER #48 is 1586780543.265148
[1,0]<stdout>:Iter #48: 122.5 img/sec per GPU took 0.522631
[1,0]<stdout>:TIME BEFORE ITER #49 is 1586780543.265215
[1,0]<stdout>:TIME AFTER ITER #49 is 1586780543.790869
[1,0]<stdout>:Iter #49: 121.8 img/sec per GPU took 0.525473
[1,0]<stdout>:TIME BEFORE ITER #50 is 1586780543.790952
[1,0]<stdout>:TIME AFTER ITER #50 is 1586780544.311741
[1,0]<stdout>:Iter #50: 122.9 img/sec per GPU took 0.520632
[1,0]<stdout>:TIME BEFORE ITER #51 is 1586780544.311821
[1,0]<stdout>:TIME AFTER ITER #51 is 1586780544.834742
[1,0]<stdout>:Iter #51: 122.4 img/sec per GPU took 0.522746
[1,0]<stdout>:TIME BEFORE ITER #52 is 1586780544.834807
[1,0]<stdout>:TIME AFTER ITER #52 is 1586780545.363295
[1,0]<stdout>:Iter #52: 121.1 img/sec per GPU took 0.528339
[1,0]<stdout>:TIME BEFORE ITER #53 is 1586780545.363368
[1,0]<stdout>:TIME AFTER ITER #53 is 1586780545.874349
[1,0]<stdout>:Iter #53: 125.3 img/sec per GPU took 0.510784
[1,0]<stdout>:TIME BEFORE ITER #54 is 1586780545.874463
[1,0]<stdout>:TIME AFTER ITER #54 is 1586780546.399025
[1,0]<stdout>:Iter #54: 122.1 img/sec per GPU took 0.524355
[1,0]<stdout>:TIME BEFORE ITER #55 is 1586780546.399117
[1,0]<stdout>:TIME AFTER ITER #55 is 1586780546.917798
[1,0]<stdout>:Iter #55: 123.4 img/sec per GPU took 0.518484
[1,0]<stdout>:TIME BEFORE ITER #56 is 1586780546.917877
[1,0]<stdout>:TIME AFTER ITER #56 is 1586780547.436586
[1,0]<stdout>:Iter #56: 123.4 img/sec per GPU took 0.518463
[1,0]<stdout>:TIME BEFORE ITER #57 is 1586780547.436666
[1,0]<stdout>:TIME AFTER ITER #57 is 1586780547.962663
[1,0]<stdout>:Iter #57: 121.7 img/sec per GPU took 0.525805
[1,0]<stdout>:TIME BEFORE ITER #58 is 1586780547.962740
[1,0]<stdout>:TIME AFTER ITER #58 is 1586780548.480939
[1,0]<stdout>:Iter #58: 123.5 img/sec per GPU took 0.518012
[1,0]<stdout>:TIME BEFORE ITER #59 is 1586780548.481016
[1,0]<stdout>:TIME AFTER ITER #59 is 1586780548.988593
[1,0]<stdout>:Iter #59: 126.1 img/sec per GPU took 0.507390
[1,0]<stdout>:TIME BEFORE ITER #60 is 1586780548.988677
[1,0]<stdout>:TIME AFTER ITER #60 is 1586780549.514611
[1,0]<stdout>:Iter #60: 121.7 img/sec per GPU took 0.525763
[1,0]<stdout>:TIME BEFORE ITER #61 is 1586780549.514683
[1,0]<stdout>:TIME AFTER ITER #61 is 1586780550.027063
[1,0]<stdout>:Iter #61: 124.9 img/sec per GPU took 0.512224
[1,0]<stdout>:TIME BEFORE ITER #62 is 1586780550.027151
[1,0]<stdout>:TIME AFTER ITER #62 is 1586780550.541425
[1,0]<stdout>:Iter #62: 124.5 img/sec per GPU took 0.514073
[1,0]<stdout>:TIME BEFORE ITER #63 is 1586780550.541511
[1,0]<stdout>:TIME AFTER ITER #63 is 1586780551.055111
[1,0]<stdout>:Iter #63: 124.7 img/sec per GPU took 0.513396
[1,0]<stdout>:TIME BEFORE ITER #64 is 1586780551.055198
[1,0]<stdout>:TIME AFTER ITER #64 is 1586780551.585626
[1,0]<stdout>:Iter #64: 120.7 img/sec per GPU took 0.530264
[1,0]<stdout>:TIME BEFORE ITER #65 is 1586780551.585690
[1,0]<stdout>:TIME AFTER ITER #65 is 1586780552.087606
[1,0]<stdout>:Iter #65: 127.6 img/sec per GPU took 0.501762
[1,0]<stdout>:TIME BEFORE ITER #66 is 1586780552.087692
[1,0]<stdout>:TIME AFTER ITER #66 is 1586780552.603878
[1,0]<stdout>:Iter #66: 124.0 img/sec per GPU took 0.515996
[1,0]<stdout>:TIME BEFORE ITER #67 is 1586780552.603967
[1,0]<stdout>:TIME AFTER ITER #67 is 1586780553.114407
[1,0]<stdout>:Iter #67: 125.4 img/sec per GPU took 0.510246
[1,0]<stdout>:TIME BEFORE ITER #68 is 1586780553.114488
[1,0]<stdout>:TIME AFTER ITER #68 is 1586780553.615787
[1,0]<stdout>:Iter #68: 127.7 img/sec per GPU took 0.501145
[1,0]<stdout>:TIME BEFORE ITER #69 is 1586780553.615846
[1,0]<stdout>:TIME AFTER ITER #69 is 1586780554.134768
[1,0]<stdout>:Iter #69: 123.4 img/sec per GPU took 0.518775
[1,0]<stdout>:TIME BEFORE ITER #70 is 1586780554.134834
[1,0]<stdout>:TIME AFTER ITER #70 is 1586780554.638751
[1,0]<stdout>:Iter #70: 127.0 img/sec per GPU took 0.503756
[1,0]<stdout>:TIME BEFORE ITER #71 is 1586780554.638833
[1,0]<stdout>:TIME AFTER ITER #71 is 1586780555.152425
[1,0]<stdout>:Iter #71: 124.7 img/sec per GPU took 0.513390
[1,0]<stdout>:TIME BEFORE ITER #72 is 1586780555.152499
[1,0]<stdout>:TIME AFTER ITER #72 is 1586780555.656357
[1,0]<stdout>:Iter #72: 127.1 img/sec per GPU took 0.503644
[1,0]<stdout>:TIME BEFORE ITER #73 is 1586780555.656417
[1,0]<stdout>:TIME AFTER ITER #73 is 1586780556.161813
[1,0]<stdout>:Iter #73: 126.7 img/sec per GPU took 0.505232
[1,0]<stdout>:TIME BEFORE ITER #74 is 1586780556.161908
[1,0]<stdout>:TIME AFTER ITER #74 is 1586780556.664705
[1,0]<stdout>:Iter #74: 127.3 img/sec per GPU took 0.502610
[1,0]<stdout>:TIME BEFORE ITER #75 is 1586780556.664766
[1,0]<stdout>:TIME AFTER ITER #75 is 1586780557.170352
[1,0]<stdout>:Iter #75: 126.6 img/sec per GPU took 0.505429
[1,0]<stdout>:TIME BEFORE ITER #76 is 1586780557.170441
[1,0]<stdout>:TIME AFTER ITER #76 is 1586780557.681876
[1,0]<stdout>:Iter #76: 125.2 img/sec per GPU took 0.511272
[1,0]<stdout>:TIME BEFORE ITER #77 is 1586780557.681951
[1,0]<stdout>:TIME AFTER ITER #77 is 1586780558.182419
[1,0]<stdout>:Iter #77: 127.9 img/sec per GPU took 0.500292
[1,0]<stdout>:TIME BEFORE ITER #78 is 1586780558.182481
[1,0]<stdout>:TIME AFTER ITER #78 is 1586780558.681124
[1,0]<stdout>:Iter #78: 128.4 img/sec per GPU took 0.498496
[1,0]<stdout>:TIME BEFORE ITER #79 is 1586780558.681188
[1,0]<stdout>:TIME AFTER ITER #79 is 1586780559.181236
[1,0]<stdout>:Iter #79: 128.0 img/sec per GPU took 0.499892
[1,0]<stdout>:TIME BEFORE ITER #80 is 1586780559.181317
[1,0]<stdout>:TIME AFTER ITER #80 is 1586780559.676326
[1,0]<stdout>:Iter #80: 129.3 img/sec per GPU took 0.494793
[1,0]<stdout>:TIME BEFORE ITER #81 is 1586780559.676401
[1,0]<stdout>:TIME AFTER ITER #81 is 1586780560.189774
[1,0]<stdout>:Iter #81: 124.7 img/sec per GPU took 0.513196
[1,0]<stdout>:TIME BEFORE ITER #82 is 1586780560.189834
[1,0]<stdout>:TIME AFTER ITER #82 is 1586780560.694439
[1,0]<stdout>:Iter #82: 126.9 img/sec per GPU took 0.504431
[1,0]<stdout>:TIME BEFORE ITER #83 is 1586780560.694509
[1,0]<stdout>:TIME AFTER ITER #83 is 1586780561.183511
[1,0]<stdout>:Iter #83: 130.9 img/sec per GPU took 0.488851
[1,0]<stdout>:TIME BEFORE ITER #84 is 1586780561.183579
[1,0]<stdout>:TIME AFTER ITER #84 is 1586780561.681883
[1,0]<stdout>:Iter #84: 128.5 img/sec per GPU took 0.498139
[1,0]<stdout>:TIME BEFORE ITER #85 is 1586780561.681944
[1,0]<stdout>:TIME AFTER ITER #85 is 1586780562.168061
[1,0]<stdout>:Iter #85: 131.7 img/sec per GPU took 0.485927
[1,0]<stdout>:TIME BEFORE ITER #86 is 1586780562.168133
[1,0]<stdout>:TIME AFTER ITER #86 is 1586780562.669884
[1,0]<stdout>:Iter #86: 127.6 img/sec per GPU took 0.501573
[1,0]<stdout>:TIME BEFORE ITER #87 is 1586780562.669943
[1,0]<stdout>:TIME AFTER ITER #87 is 1586780563.163371
[1,0]<stdout>:Iter #87: 129.7 img/sec per GPU took 0.493289
[1,0]<stdout>:TIME BEFORE ITER #88 is 1586780563.163447
[1,0]<stdout>:TIME AFTER ITER #88 is 1586780563.660258
[1,0]<stdout>:Iter #88: 128.9 img/sec per GPU took 0.496612
[1,0]<stdout>:TIME BEFORE ITER #89 is 1586780563.660330
[1,0]<stdout>:TIME AFTER ITER #89 is 1586780564.154050
[1,0]<stdout>:Iter #89: 129.7 img/sec per GPU took 0.493532
[1,0]<stdout>:TIME BEFORE ITER #90 is 1586780564.154145
[1,0]<stdout>:TIME AFTER ITER #90 is 1586780564.668869
[1,0]<stdout>:Iter #90: 124.4 img/sec per GPU took 0.514501
[1,0]<stdout>:TIME BEFORE ITER #91 is 1586780564.668943
[1,0]<stdout>:TIME AFTER ITER #91 is 1586780565.171735
[1,0]<stdout>:Iter #91: 127.3 img/sec per GPU took 0.502607
[1,0]<stdout>:TIME BEFORE ITER #92 is 1586780565.171814
[1,0]<stdout>:TIME AFTER ITER #92 is 1586780565.664944
[1,0]<stdout>:Iter #92: 129.8 img/sec per GPU took 0.492925
[1,0]<stdout>:TIME BEFORE ITER #93 is 1586780565.665019
[1,0]<stdout>:TIME AFTER ITER #93 is 1586780566.157906
[1,0]<stdout>:Iter #93: 129.9 img/sec per GPU took 0.492711
[1,0]<stdout>:TIME BEFORE ITER #94 is 1586780566.158007
[1,0]<stdout>:TIME AFTER ITER #94 is 1586780566.647624
[1,0]<stdout>:Iter #94: 130.8 img/sec per GPU took 0.489418
[1,0]<stdout>:TIME BEFORE ITER #95 is 1586780566.647947
[1,0]<stdout>:TIME AFTER ITER #95 is 1586780567.144936
[1,0]<stdout>:Iter #95: 128.8 img/sec per GPU took 0.496734
[1,0]<stdout>:TIME BEFORE ITER #96 is 1586780567.144995
[1,0]<stdout>:TIME AFTER ITER #96 is 1586780567.632111
[1,0]<stdout>:Iter #96: 131.4 img/sec per GPU took 0.486969
[1,0]<stdout>:TIME BEFORE ITER #97 is 1586780567.632210
[1,0]<stdout>:TIME AFTER ITER #97 is 1586780568.124107
[1,0]<stdout>:Iter #97: 130.2 img/sec per GPU took 0.491708
[1,0]<stdout>:TIME BEFORE ITER #98 is 1586780568.124179
[1,0]<stdout>:TIME AFTER ITER #98 is 1586780568.623387
[1,0]<stdout>:Iter #98: 128.2 img/sec per GPU took 0.499039
[1,0]<stdout>:TIME BEFORE ITER #99 is 1586780568.623461
[1,0]<stdout>:TIME AFTER ITER #99 is 1586780569.118860
[1,0]<stdout>:Iter #99: 129.2 img/sec per GPU took 0.495232
[1,0]<stdout>:TIME BEFORE ITER #100 is 1586780569.118965
[1,0]<stdout>:TIME AFTER ITER #100 is 1586780569.606796
[1,0]<stdout>:Iter #100: 131.3 img/sec per GPU took 0.487579
[1,0]<stdout>:TIME BEFORE ITER #101 is 1586780569.606873
[1,0]<stdout>:TIME AFTER ITER #101 is 1586780570.111028
[1,0]<stdout>:Iter #101: 127.0 img/sec per GPU took 0.503983
[1,0]<stdout>:TIME BEFORE ITER #102 is 1586780570.111109
[1,0]<stdout>:TIME AFTER ITER #102 is 1586780570.631304
[1,0]<stdout>:Iter #102: 123.1 img/sec per GPU took 0.519952
[1,0]<stdout>:TIME BEFORE ITER #103 is 1586780570.631389
[1,0]<stdout>:TIME AFTER ITER #103 is 1586780571.120716
[1,0]<stdout>:Iter #103: 130.8 img/sec per GPU took 0.489124
[1,0]<stdout>:TIME BEFORE ITER #104 is 1586780571.120797
[1,0]<stdout>:TIME AFTER ITER #104 is 1586780571.614253
[1,0]<stdout>:Iter #104: 129.7 img/sec per GPU took 0.493256
[1,0]<stdout>:TIME BEFORE ITER #105 is 1586780571.614352
[1,0]<stdout>:TIME AFTER ITER #105 is 1586780572.114711
[1,0]<stdout>:Iter #105: 128.0 img/sec per GPU took 0.500173
[1,0]<stdout>:TIME BEFORE ITER #106 is 1586780572.114790
[1,0]<stdout>:TIME AFTER ITER #106 is 1586780572.603947
[1,0]<stdout>:Iter #106: 130.9 img/sec per GPU took 0.488950
[1,0]<stdout>:TIME BEFORE ITER #107 is 1586780572.604011
[1,0]<stdout>:TIME AFTER ITER #107 is 1586780573.108469
[1,0]<stdout>:Iter #107: 126.9 img/sec per GPU took 0.504137
[1,0]<stdout>:TIME BEFORE ITER #108 is 1586780573.108554
[1,0]<stdout>:TIME AFTER ITER #108 is 1586780573.604688
[1,0]<stdout>:Iter #108: 129.0 img/sec per GPU took 0.495956
[1,0]<stdout>:TIME BEFORE ITER #109 is 1586780573.604748
[1,0]<stdout>:TIME AFTER ITER #109 is 1586780574.101704
[1,0]<stdout>:Iter #109: 128.8 img/sec per GPU took 0.496780
[1,0]<stdout>:TIME BEFORE ITER #110 is 1586780574.101788
[1,0]<stdout>:TIME AFTER ITER #110 is 1586780574.598234
[1,0]<stdout>:Iter #110: 129.0 img/sec per GPU took 0.496257
[1,0]<stdout>:TIME BEFORE ITER #111 is 1586780574.598352
[1,0]<stdout>:TIME AFTER ITER #111 is 1586780575.088536
[1,0]<stdout>:Iter #111: 130.6 img/sec per GPU took 0.489963
[1,0]<stdout>:TIME BEFORE ITER #112 is 1586780575.088598
[1,0]<stdout>:TIME AFTER ITER #112 is 1586780575.590690
[1,0]<stdout>:Iter #112: 127.5 img/sec per GPU took 0.501909
[1,0]<stdout>:TIME BEFORE ITER #113 is 1586780575.590774
[1,0]<stdout>:TIME AFTER ITER #113 is 1586780576.091281
[1,0]<stdout>:Iter #113: 127.9 img/sec per GPU took 0.500321
[1,0]<stdout>:TIME BEFORE ITER #114 is 1586780576.091363
[1,0]<stdout>:TIME AFTER ITER #114 is 1586780576.591716
[1,0]<stdout>:Iter #114: 128.0 img/sec per GPU took 0.500172
[1,0]<stdout>:TIME BEFORE ITER #115 is 1586780576.591795
[1,0]<stdout>:TIME AFTER ITER #115 is 1586780577.131409
[1,0]<stdout>:Iter #115: 118.6 img/sec per GPU took 0.539424
[1,0]<stdout>:TIME BEFORE ITER #116 is 1586780577.131472
[1,0]<stdout>:TIME AFTER ITER #116 is 1586780577.608304
[1,0]<stdout>:Iter #116: 134.3 img/sec per GPU took 0.476691
[1,0]<stdout>:TIME BEFORE ITER #117 is 1586780577.608370
[1,0]<stdout>:TIME AFTER ITER #117 is 1586780578.098394
[1,0]<stdout>:Iter #117: 130.6 img/sec per GPU took 0.489880
[1,0]<stdout>:TIME BEFORE ITER #118 is 1586780578.098481
[1,0]<stdout>:TIME AFTER ITER #118 is 1586780578.615405
[1,0]<stdout>:Iter #118: 123.9 img/sec per GPU took 0.516742
[1,0]<stdout>:TIME BEFORE ITER #119 is 1586780578.615485
[1,0]<stdout>:TIME AFTER ITER #119 is 1586780579.125745
[1,0]<stdout>:Iter #119: 125.5 img/sec per GPU took 0.510056
[1,0]<stdout>:TIME BEFORE ITER #120 is 1586780579.125813
[1,0]<stdout>:TIME AFTER ITER #120 is 1586780579.629642
[1,0]<stdout>:Iter #120: 127.1 img/sec per GPU took 0.503685
[1,0]<stdout>:TIME BEFORE ITER #121 is 1586780579.629716
[1,0]<stdout>:TIME AFTER ITER #121 is 1586780580.118920
[1,0]<stdout>:Iter #121: 130.9 img/sec per GPU took 0.489032
[1,0]<stdout>:TIME BEFORE ITER #122 is 1586780580.118988
[1,0]<stdout>:TIME AFTER ITER #122 is 1586780580.606070
[1,0]<stdout>:Iter #122: 131.4 img/sec per GPU took 0.486902
[1,0]<stdout>:TIME BEFORE ITER #123 is 1586780580.606132
[1,0]<stdout>:TIME AFTER ITER #123 is 1586780581.102361
[1,0]<stdout>:Iter #123: 129.0 img/sec per GPU took 0.496042
[1,0]<stdout>:TIME BEFORE ITER #124 is 1586780581.102434
[1,0]<stdout>:TIME AFTER ITER #124 is 1586780581.611346
[1,0]<stdout>:Iter #124: 125.8 img/sec per GPU took 0.508744
[1,0]<stdout>:TIME BEFORE ITER #125 is 1586780581.611417
[1,0]<stdout>:TIME AFTER ITER #125 is 1586780582.094444
[1,0]<stdout>:Iter #125: 132.5 img/sec per GPU took 0.482861
[1,0]<stdout>:TIME BEFORE ITER #126 is 1586780582.094531
[1,0]<stdout>:TIME AFTER ITER #126 is 1586780582.589317
[1,0]<stdout>:Iter #126: 129.4 img/sec per GPU took 0.494588
[1,0]<stdout>:TIME BEFORE ITER #127 is 1586780582.589380
[1,0]<stdout>:TIME AFTER ITER #127 is 1586780583.089380
[1,0]<stdout>:Iter #127: 128.0 img/sec per GPU took 0.499858
[1,0]<stdout>:TIME BEFORE ITER #128 is 1586780583.089459
[1,0]<stdout>:TIME AFTER ITER #128 is 1586780583.585337
[1,0]<stdout>:Iter #128: 129.1 img/sec per GPU took 0.495707
[1,0]<stdout>:TIME BEFORE ITER #129 is 1586780583.585404
[1,0]<stdout>:TIME AFTER ITER #129 is 1586780584.083799
[1,0]<stdout>:Iter #129: 128.5 img/sec per GPU took 0.498237
[1,0]<stdout>:TIME BEFORE ITER #130 is 1586780584.083862
[1,0]<stdout>:TIME AFTER ITER #130 is 1586780584.574439
[1,0]<stdout>:Iter #130: 130.5 img/sec per GPU took 0.490432
[1,0]<stdout>:TIME BEFORE ITER #131 is 1586780584.574500
[1,0]<stdout>:TIME AFTER ITER #131 is 1586780585.075910
[1,0]<stdout>:Iter #131: 127.7 img/sec per GPU took 0.501254
[1,0]<stdout>:TIME BEFORE ITER #132 is 1586780585.075998
[1,0]<stdout>:TIME AFTER ITER #132 is 1586780585.571193
[1,0]<stdout>:Iter #132: 129.3 img/sec per GPU took 0.495007
[1,0]<stdout>:TIME BEFORE ITER #133 is 1586780585.571260
[1,0]<stdout>:TIME AFTER ITER #133 is 1586780586.053776
[1,0]<stdout>:Iter #133: 132.7 img/sec per GPU took 0.482351
[1,0]<stdout>:TIME BEFORE ITER #134 is 1586780586.053841
[1,0]<stdout>:TIME AFTER ITER #134 is 1586780586.542028
[1,0]<stdout>:Iter #134: 131.1 img/sec per GPU took 0.488036
[1,0]<stdout>:TIME BEFORE ITER #135 is 1586780586.542117
[1,0]<stdout>:TIME AFTER ITER #135 is 1586780587.041647
[1,0]<stdout>:Iter #135: 128.2 img/sec per GPU took 0.499300
[1,0]<stdout>:TIME BEFORE ITER #136 is 1586780587.041729
[1,0]<stdout>:TIME AFTER ITER #136 is 1586780587.526208
[1,0]<stdout>:Iter #136: 132.2 img/sec per GPU took 0.484265
[1,0]<stdout>:TIME BEFORE ITER #137 is 1586780587.526325
[1,0]<stdout>:TIME AFTER ITER #137 is 1586780588.013927
[1,0]<stdout>:Iter #137: 131.3 img/sec per GPU took 0.487404
[1,0]<stdout>:TIME BEFORE ITER #138 is 1586780588.014010
[1,0]<stdout>:TIME AFTER ITER #138 is 1586780588.506591
[1,0]<stdout>:Iter #138: 130.0 img/sec per GPU took 0.492394
[1,0]<stdout>:TIME BEFORE ITER #139 is 1586780588.506703
[1,0]<stdout>:TIME AFTER ITER #139 is 1586780588.994622
[1,0]<stdout>:Iter #139: 131.2 img/sec per GPU took 0.487669
[1,0]<stdout>:TIME BEFORE ITER #140 is 1586780588.994698
[1,0]<stdout>:TIME AFTER ITER #140 is 1586780589.484665
[1,0]<stdout>:Iter #140: 130.7 img/sec per GPU took 0.489777
[1,0]<stdout>:TIME BEFORE ITER #141 is 1586780589.484747
[1,0]<stdout>:TIME AFTER ITER #141 is 1586780589.973541
[1,0]<stdout>:Iter #141: 131.0 img/sec per GPU took 0.488618
[1,0]<stdout>:TIME BEFORE ITER #142 is 1586780589.973603
[1,0]<stdout>:TIME AFTER ITER #142 is 1586780590.457027
[1,0]<stdout>:Iter #142: 132.4 img/sec per GPU took 0.483282
[1,0]<stdout>:TIME BEFORE ITER #143 is 1586780590.457129
[1,0]<stdout>:TIME AFTER ITER #143 is 1586780590.946825
[1,0]<stdout>:Iter #143: 130.7 img/sec per GPU took 0.489503
[1,0]<stdout>:TIME BEFORE ITER #144 is 1586780590.946894
[1,0]<stdout>:TIME AFTER ITER #144 is 1586780591.440325
[1,0]<stdout>:Iter #144: 129.8 img/sec per GPU took 0.493246
[1,0]<stdout>:TIME BEFORE ITER #145 is 1586780591.440416
[1,0]<stdout>:TIME AFTER ITER #145 is 1586780591.933321
[1,0]<stdout>:Iter #145: 129.9 img/sec per GPU took 0.492722
[1,0]<stdout>:TIME BEFORE ITER #146 is 1586780591.933385
[1,0]<stdout>:TIME AFTER ITER #146 is 1586780592.434265
[1,0]<stdout>:Iter #146: 127.8 img/sec per GPU took 0.500720
[1,0]<stdout>:TIME BEFORE ITER #147 is 1586780592.434381
[1,0]<stdout>:TIME AFTER ITER #147 is 1586780592.918169
[1,0]<stdout>:Iter #147: 132.3 img/sec per GPU took 0.483587
[1,0]<stdout>:TIME BEFORE ITER #148 is 1586780592.918244
[1,0]<stdout>:TIME AFTER ITER #148 is 1586780593.413963
[1,0]<stdout>:Iter #148: 129.2 img/sec per GPU took 0.495518
[1,0]<stdout>:TIME BEFORE ITER #149 is 1586780593.414049
[1,0]<stdout>:TIME AFTER ITER #149 is 1586780593.900208
[1,0]<stdout>:Iter #149: 131.7 img/sec per GPU took 0.485971
[1,0]<stdout>:TIME BEFORE ITER #150 is 1586780593.900283
[1,0]<stdout>:TIME AFTER ITER #150 is 1586780594.380031
[1,0]<stdout>:Iter #150: 133.4 img/sec per GPU took 0.479595
[1,0]<stdout>:TIME BEFORE ITER #151 is 1586780594.380130
[1,0]<stdout>:TIME AFTER ITER #151 is 1586780594.871000
[1,0]<stdout>:Iter #151: 130.4 img/sec per GPU took 0.490693
[1,0]<stdout>:TIME BEFORE ITER #152 is 1586780594.871089
[1,0]<stdout>:TIME AFTER ITER #152 is 1586780595.368255
[1,0]<stdout>:Iter #152: 128.8 img/sec per GPU took 0.496997
[1,0]<stdout>:TIME BEFORE ITER #153 is 1586780595.368337
[1,0]<stdout>:TIME AFTER ITER #153 is 1586780595.860373
[1,0]<stdout>:Iter #153: 130.1 img/sec per GPU took 0.491883
[1,0]<stdout>:TIME BEFORE ITER #154 is 1586780595.860440
[1,0]<stdout>:TIME AFTER ITER #154 is 1586780596.357348
[1,0]<stdout>:Iter #154: 128.8 img/sec per GPU took 0.496748
[1,0]<stdout>:TIME BEFORE ITER #155 is 1586780596.357421
[1,0]<stdout>:TIME AFTER ITER #155 is 1586780596.865864
[1,0]<stdout>:Iter #155: 125.9 img/sec per GPU took 0.508296
[1,0]<stdout>:TIME BEFORE ITER #156 is 1586780596.865928
[1,0]<stdout>:TIME AFTER ITER #156 is 1586780597.366196
[1,0]<stdout>:Iter #156: 128.0 img/sec per GPU took 0.500116
[1,0]<stdout>:TIME BEFORE ITER #157 is 1586780597.366262
[1,0]<stdout>:TIME AFTER ITER #157 is 1586780597.859499
[1,0]<stdout>:Iter #157: 129.8 img/sec per GPU took 0.493067
[1,0]<stdout>:TIME BEFORE ITER #158 is 1586780597.859583
[1,0]<stdout>:TIME AFTER ITER #158 is 1586780598.370174
[1,0]<stdout>:Iter #158: 125.4 img/sec per GPU took 0.510435
[1,0]<stdout>:TIME BEFORE ITER #159 is 1586780598.370253
[1,0]<stdout>:TIME AFTER ITER #159 is 1586780598.858370
[1,0]<stdout>:Iter #159: 131.2 img/sec per GPU took 0.487935
[1,0]<stdout>:TIME BEFORE ITER #160 is 1586780598.858446
[1,0]<stdout>:TIME AFTER ITER #160 is 1586780599.360248
[1,0]<stdout>:Iter #160: 127.6 img/sec per GPU took 0.501648
[1,0]<stdout>:TIME BEFORE ITER #161 is 1586780599.360322
[1,0]<stdout>:TIME AFTER ITER #161 is 1586780599.849838
[1,0]<stdout>:Iter #161: 130.8 img/sec per GPU took 0.489335
[1,0]<stdout>:TIME BEFORE ITER #162 is 1586780599.849936
[1,0]<stdout>:TIME AFTER ITER #162 is 1586780600.343692
[1,0]<stdout>:Iter #162: 129.7 img/sec per GPU took 0.493535
[1,0]<stdout>:TIME BEFORE ITER #163 is 1586780600.343797
[1,0]<stdout>:TIME AFTER ITER #163 is 1586780600.836417
[1,0]<stdout>:Iter #163: 130.0 img/sec per GPU took 0.492364
[1,0]<stdout>:TIME BEFORE ITER #164 is 1586780600.836521
[1,0]<stdout>:TIME AFTER ITER #164 is 1586780601.336702
[1,0]<stdout>:Iter #164: 128.0 img/sec per GPU took 0.499937
[1,0]<stdout>:TIME BEFORE ITER #165 is 1586780601.336768
[1,0]<stdout>:TIME AFTER ITER #165 is 1586780601.845931
[1,0]<stdout>:Iter #165: 125.7 img/sec per GPU took 0.508998
[1,0]<stdout>:TIME BEFORE ITER #166 is 1586780601.845996
[1,0]<stdout>:TIME AFTER ITER #166 is 1586780602.332958
[1,0]<stdout>:Iter #166: 131.5 img/sec per GPU took 0.486815
[1,0]<stdout>:TIME BEFORE ITER #167 is 1586780602.333021
[1,0]<stdout>:TIME AFTER ITER #167 is 1586780602.836954
[1,0]<stdout>:Iter #167: 127.1 img/sec per GPU took 0.503717
[1,0]<stdout>:TIME BEFORE ITER #168 is 1586780602.837026
[1,0]<stdout>:TIME AFTER ITER #168 is 1586780603.325580
[1,0]<stdout>:Iter #168: 131.0 img/sec per GPU took 0.488400
[1,0]<stdout>:TIME BEFORE ITER #169 is 1586780603.325639
[1,0]<stdout>:TIME AFTER ITER #169 is 1586780603.820585
[1,0]<stdout>:Iter #169: 129.3 img/sec per GPU took 0.494793
[1,0]<stdout>:TIME BEFORE ITER #170 is 1586780603.820658
[1,0]<stdout>:TIME AFTER ITER #170 is 1586780604.322669
[1,0]<stdout>:Iter #170: 127.5 img/sec per GPU took 0.501850
[1,0]<stdout>:TIME BEFORE ITER #171 is 1586780604.322759
[1,0]<stdout>:TIME AFTER ITER #171 is 1586780604.803943
[1,0]<stdout>:Iter #171: 133.1 img/sec per GPU took 0.480984
[1,0]<stdout>:TIME BEFORE ITER #172 is 1586780604.804025
[1,0]<stdout>:TIME AFTER ITER #172 is 1586780605.306685
[1,0]<stdout>:Iter #172: 127.4 img/sec per GPU took 0.502490
[1,0]<stdout>:TIME BEFORE ITER #173 is 1586780605.306761
[1,0]<stdout>:TIME AFTER ITER #173 is 1586780605.803581
[1,0]<stdout>:Iter #173: 128.9 img/sec per GPU took 0.496637
[1,0]<stdout>:TIME BEFORE ITER #174 is 1586780605.803668
[1,0]<stdout>:TIME AFTER ITER #174 is 1586780606.288130
[1,0]<stdout>:Iter #174: 132.2 img/sec per GPU took 0.484288
[1,0]<stdout>:TIME BEFORE ITER #175 is 1586780606.288199
[1,0]<stdout>:TIME AFTER ITER #175 is 1586780606.788697
[1,0]<stdout>:Iter #175: 127.9 img/sec per GPU took 0.500305
[1,0]<stdout>:TIME BEFORE ITER #176 is 1586780606.788762
[1,0]<stdout>:TIME AFTER ITER #176 is 1586780607.289958
[1,0]<stdout>:Iter #176: 127.7 img/sec per GPU took 0.501052
[1,0]<stdout>:TIME BEFORE ITER #177 is 1586780607.290033
[1,0]<stdout>:TIME AFTER ITER #177 is 1586780607.803080
[1,0]<stdout>:Iter #177: 124.8 img/sec per GPU took 0.512851
[1,0]<stdout>:TIME BEFORE ITER #178 is 1586780607.803247
[1,0]<stdout>:TIME AFTER ITER #178 is 1586780608.292136
[1,0]<stdout>:Iter #178: 131.0 img/sec per GPU took 0.488666
[1,0]<stdout>:TIME BEFORE ITER #179 is 1586780608.292246
[1,0]<stdout>:TIME AFTER ITER #179 is 1586780608.793485
[1,0]<stdout>:Iter #179: 127.7 img/sec per GPU took 0.500995
[1,0]<stdout>:TIME BEFORE ITER #180 is 1586780608.793563
[1,0]<stdout>:TIME AFTER ITER #180 is 1586780609.297183
[1,0]<stdout>:Iter #180: 127.1 img/sec per GPU took 0.503467
[1,0]<stdout>:TIME BEFORE ITER #181 is 1586780609.297260
[1,0]<stdout>:TIME AFTER ITER #181 is 1586780609.810320
[1,0]<stdout>:Iter #181: 124.8 img/sec per GPU took 0.512866
[1,0]<stdout>:TIME BEFORE ITER #182 is 1586780609.810381
[1,0]<stdout>:TIME AFTER ITER #182 is 1586780610.321795
[1,0]<stdout>:Iter #182: 125.2 img/sec per GPU took 0.511265
[1,0]<stdout>:TIME BEFORE ITER #183 is 1586780610.321869
[1,0]<stdout>:TIME AFTER ITER #183 is 1586780610.845142
[1,0]<stdout>:Iter #183: 122.4 img/sec per GPU took 0.523052
[1,0]<stdout>:TIME BEFORE ITER #184 is 1586780610.845524
[1,0]<stdout>:TIME AFTER ITER #184 is 1586780611.376891
[1,0]<stdout>:Iter #184: 120.5 img/sec per GPU took 0.531221
[1,0]<stdout>:TIME BEFORE ITER #185 is 1586780611.376972
[1,0]<stdout>:TIME AFTER ITER #185 is 1586780611.875333
[1,0]<stdout>:Iter #185: 128.5 img/sec per GPU took 0.498215
[1,0]<stdout>:TIME BEFORE ITER #186 is 1586780611.875398
[1,0]<stdout>:TIME AFTER ITER #186 is 1586780612.378312
[1,0]<stdout>:Iter #186: 127.3 img/sec per GPU took 0.502731
[1,0]<stdout>:TIME BEFORE ITER #187 is 1586780612.378406
[1,0]<stdout>:TIME AFTER ITER #187 is 1586780612.867541
[1,0]<stdout>:Iter #187: 130.9 img/sec per GPU took 0.488942
[1,0]<stdout>:TIME BEFORE ITER #188 is 1586780612.867616
[1,0]<stdout>:TIME AFTER ITER #188 is 1586780613.363581
[1,0]<stdout>:Iter #188: 129.1 img/sec per GPU took 0.495775
[1,0]<stdout>:TIME BEFORE ITER #189 is 1586780613.363659
[1,0]<stdout>:TIME AFTER ITER #189 is 1586780613.872427
[1,0]<stdout>:Iter #189: 125.8 img/sec per GPU took 0.508604
[1,0]<stdout>:TIME BEFORE ITER #190 is 1586780613.872502
[1,0]<stdout>:TIME AFTER ITER #190 is 1586780614.361537
[1,0]<stdout>:Iter #190: 130.9 img/sec per GPU took 0.488837
[1,0]<stdout>:TIME BEFORE ITER #191 is 1586780614.361603
[1,0]<stdout>:TIME AFTER ITER #191 is 1586780614.885658
[1,0]<stdout>:Iter #191: 122.2 img/sec per GPU took 0.523874
[1,0]<stdout>:TIME BEFORE ITER #192 is 1586780614.885734
[1,0]<stdout>:TIME AFTER ITER #192 is 1586780615.383067
[1,0]<stdout>:Iter #192: 128.7 img/sec per GPU took 0.497149
[1,0]<stdout>:TIME BEFORE ITER #193 is 1586780615.383157
[1,0]<stdout>:TIME AFTER ITER #193 is 1586780615.885949
[1,0]<stdout>:Iter #193: 127.3 img/sec per GPU took 0.502604
[1,0]<stdout>:TIME BEFORE ITER #194 is 1586780615.886017
[1,0]<stdout>:TIME AFTER ITER #194 is 1586780616.384555
[1,0]<stdout>:Iter #194: 128.4 img/sec per GPU took 0.498381
[1,0]<stdout>:TIME BEFORE ITER #195 is 1586780616.384619
[1,0]<stdout>:TIME AFTER ITER #195 is 1586780616.895407
[1,0]<stdout>:Iter #195: 125.3 img/sec per GPU took 0.510605
[1,0]<stdout>:TIME BEFORE ITER #196 is 1586780616.895510
[1,0]<stdout>:TIME AFTER ITER #196 is 1586780617.389979
[1,0]<stdout>:Iter #196: 129.5 img/sec per GPU took 0.494233
[1,0]<stdout>:TIME BEFORE ITER #197 is 1586780617.390072
[1,0]<stdout>:TIME AFTER ITER #197 is 1586780617.888532
[1,0]<stdout>:Iter #197: 128.5 img/sec per GPU took 0.498237
[1,0]<stdout>:TIME BEFORE ITER #198 is 1586780617.888638
[1,0]<stdout>:TIME AFTER ITER #198 is 1586780618.406572
[1,0]<stdout>:Iter #198: 123.6 img/sec per GPU took 0.517746
[1,0]<stdout>:TIME BEFORE ITER #199 is 1586780618.406804
[1,0]<stdout>:TIME AFTER ITER #199 is 1586780618.901218
[1,0]<stdout>:Iter #199: 129.5 img/sec per GPU took 0.494205
[1,0]<stdout>:Img/sec per GPU: 127.7 +-5.9
[1,0]<stdout>:Total img/sec on 16 GPU(s): 2043.5 +-94.6
[hvd-t4-vm-1:06743] PMIX ERROR: BAD-PARAM in file src/dstore/pmix_esh.c at line 491
